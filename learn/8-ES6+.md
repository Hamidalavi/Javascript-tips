# Some **`ES6 & Beyond`** snippets to give you more information

If you've been writing JS for any length of time, odds are the syntax is pretty familiar to you. There are certainly many quirks, but overall it's a fairly reasonable and straightforward syntax that draws many similarities from other languages. However, **ES6** adds quite a few new syntactic forms that take some getting used to. In this chapter, we'll tour through them to find out what's in store.

**Tip**: At the time of this writing, some of the features discussed in this book have been implemented in various browsers (Firefox, Chrome, etc.), but some have only been partially implemented and many others have not been implemented at all. Your experience may be mixed trying these examples directly. If so, try them out with transpilers, as most of these features are covered by those tools. trying out **ES6**, as is the online REPL for the Babel transpiler <http://babeljs.io/repl>.

## Block-Scoped Declarations

You're probably aware that the fundamental unit of variable scoping in **JavaScript** has always been the `function`. If you needed to create a block of scope, the most prevalent way to do so other than a regular function declaration was the **immediately invoked function expression** (IIFE). For example:

```js
var hamid = 23;
(function IIFE() {
  var hamid = 24;
  console.log(hamid); // 24
})();

console.log(hamid); // 23
```

If you remove `var` from block, output will differrent. Because `hamid` referencing to `global hamid` (first `hamid` declaration):

```js
var hamid = 23;
(function IIFE() {
  hamid = 24;
  console.log(hamid); // 24
})();

console.log(hamid); // 24
```

## `let` Declarations/Initialization

However, we can now create declarations that are bound to any block, called **block scoping**. This means all we need is a pair of `{ .. }` to create a scope. Instead of using `var`, which always declares variables attached to the enclosing function (or global, if top level) scope, use `let`:

```js
let hamed = 23;

{
  let hamed = 24;
  console.log(hamed); // 24
}

console.log(hamed); // 23
```

It's not very common or idiomatic thus far in JS to use a standalone `{ .. }` block, but it's always been valid. And developers from other languages that have block scoping will readily recognize that pattern.

We believe this is the best way to create block-scoped variables, with a dedicated `{ .. }` block. Moreover, you should always put the `let` declaration(s) at the very top of that block. If you have more than one to declare, we'd recommend using just one `let`.

Stylistically, we even prefer to put the `{`, to make it clearer that this block is only for the purpose of declaring the scope for those variables.

```js
{
  let ali = 22, reza, majid, mehrdad, morteza;
}
```

There's another experimental (not standardized) form of the `let` declaration called the `let`-block, which looks like:

```js
let(ali = 22, reza, majid, mehrdad, morteza); {
  // do something
}
```

That form is what we call explicit block scoping, whereas the `let ..` declaration form that mirrors `var` is more implicit, as it kind of hijacks whatever `{ .. }` pair it's found in. Generally developers find explicit mechanisms a bit more preferable than implicit mechanisms, and We claim this is one of those cases.

If you compare the previous two snippet forms, they're very similar, and in our opinion both qualify stylistically as explicit block scoping. Unfortunately, the `let (..) { .. }` form, the most explicit of the options, was not adopted in **ES6**. That may be revisited post-**ES6**, but for now the former option is our best bet, **I** think.

Accessing a `let`-declared variable earlier than its `let ..` declaration/initialization causes an error, whereas with `var` declarations the ordering doesn't matter (except stylistically).Look below snippet:

```js
console.log(hamed); // undefined
console.log(hamid); // ReferenceError: Cannot access 'hamid' before initialization

var hamed;
let hamid;
```

**Warning**: This `ReferenceError` from accessing too-early `let`-declared references is technically called a Temporal Dead Zone (TDZ) error -- you're accessing a variable that's been declared but not yet initialized. This will not be the only time we see TDZ errors -- they crop up in several places in **ES6**. Also, note that **initialized** doesn't require explicitly assigning a value in your code, as `let hamid;` is totally valid. A variable that's not given an assignment at declaration time is assumed to have been assigned the `undefined` value, so `let hamid;` is the same as `let hamid = undefined;`. Explicit assignment or not, you cannot access `hamid` until the `let hamid` statement is run.

One last gotcha: `typeof` behaves differently with TDZ variables than it does with undeclared (or declared!) variables. For example:

```js
{
  // `hamed` is not declared
  if (typeof hamed === "undefined") {
    console.log("Yeah!");
  }

  // `hamid` is declared, but in its TDZ
  if (typeof hamid === "undefined") { // ReferenceError!
    // ..
  }

  // ..

  let hamid;
}
```

The `hamed` is not declared, so `typeof` is the only safe way to check for its existence or not. But `typeof hamid` throws the TDZ error because farther down in the code there happens to be a `let hamid` declaration.

Now it should be clearer why we insist that `let` declarations should all be at the top of their scope. That totally avoids the accidental errors of accessing too early. It also makes it more explicit when you look at the start of a block, any block, what variables it contains.

Your blocks (`if` statements, `while` loops, etc.) don't have to share their original behavior with scoping behavior. This explicitness on your part, which is up to you to maintain with discipline, will save you lots of refactor headaches and footguns down the line.

## `let` + `for`

The only exception we'd make to the preference for the explicit form of `let` declaration blocking is a `let` that appears in the header of a `for` loop. The reason may seem nuanced, but we believe it to be one of the more important **ES6** features. Consider:

```js
var funcs = [];
for (let i = 0; i < 5; i++) {
  funcs.push(function () {
    console.log(i);
  });
}

funcs[4](); // 4
```

The `let i` in the `for` header declares an `i` not just for the `for` loop itself, but it redeclares a new `i` for each iteration of the loop. That means that closures created inside the loop iteration close over those per-iteration variables the way you'd expect.

If you tried that same snippet but with `var i` in the `for` loop header, you'd get `5` instead of `4`, because there'd only be one `i` in the outer scope that was closed over, instead of a new `i` for each iteration's function to close over. You could also have accomplished the same thing slightly more verbosely:

```js
var funcs = [];
for (var i = 0; i < 5; i++) {
  let j = i;
  funcs.push(function () {
    console.log(j);
  });
}

funcs[4](); // 4
```

Wihout `let j`:

```js
var funcs = [];
for (var i = 0; i < 5; i++) {
  funcs.push(function () {
    console.log(i);
  });
}

funcs[4](); // 5
```

Here (previous code), we forcibly create a new `j` for each iteration, and then the closure works the same way. We prefer the former approach; that extra special capability is why We endorse the `for (let .. ) ..` form. It could be argued it's somewhat more implicit, but it's explicit enough, and useful enough, for our tastes.

`let` also works the same way with `for..in` and `for..of` loops.

## `const` Declarations

There's one other form of block-scoped declaration to consider: the `const`, which creates constants.

What exactly is a constant? It's a variable that's read-only after its initial value is set. Consider:

```js
const hamid = 23;
console.log(hamid); // 23
hamid = 24; // TypeError: Assignment to constant variable
```

You are not allowed to change the value the variable holds once it's been set, at declaration time. A `const` declaration must have an explicit initialization. If you wanted a constant with the `undefined` value, you'd have to declare `const hamid = undefined` to get it.

Constants are not a restriction on the value itself, but on the variable's assignment of that value. In other words, the value is not frozen or immutable because of `const`, just the assignment of it. If the value is complex, such as an object or array, the contents of the value can still be modified:

```js
const hamid = [1, 2, 3, 4];
hamid.push(5);
console.log(hamid); // [ 1, 2, 3, 4, 5 ]
hamid = 23; // TypeError: Assignment to constant variable
```

The `hamid` variable doesn't actually hold a constant array; rather, it holds a constant reference to the array. The array itself is freely mutable.

**Warning**: Assigning an object or array as a constant means that value will not be able to be garbage collected until that constant's lexical scope goes away, as the reference to the value can never be unset. That may be desirable, but be careful if it's not your intent!

**Tip**: We recommend to use UPPERCASE in `const` like `const HAMID`.

`const` can be used with variable declarations of `for`, `for..in`, and `for..of` loops. However, an error will be thrown if there's any attempt to reassign, such as the typical `i++` clause of a `for` loop.

---

There's some rumored assumptions that a `const` could be more optimizable by the **JavaScript** engine in certain scenarios than a `let` and `var` would be. Theoretically, the engine more easily knows the variable's value/type will never change, so it can eliminate some possible tracking.

Whether`const` really helps here or this is just our own fantasies and intuitions, the much more important decision to make is if you intend constant behavior or not. Remember: one of the most important roles for source code is to communicate clearly, not only to you, but your future self and other code collaborators, what is your intent is.

Some developers prefer to start out every variable declaration as a `const` and then relax a declaration back to a `let` if it becomes necessary for its value to change in the code. This is an interesting perspective, but it's not clear that it genuinely improves the readability or reason-ability of code.

**Our advice**: To avoid potentially confusing code, only use `const` for variables that you're intentionally and obviously signaling will not change. In other words, don't rely on `const` for code behavior, but instead use it as a tool for signaling intent, when intent can be signaled clearly.

## Block-scoped Functions

Look below snippets:

```js
{
  hamid(); // "Persian Sight"

  function hamid() {
    console.log("Persian Sight");
  }
}

hamid(); // "Persian Sight"
```

```js
"use strict"
{
  hamid(); // "Persian Sight"

  function hamid() {
    console.log("Persian Sight");
  }
}

hamid(); // ReferenceError: hamid is not defined
```

The `hamid()` function is declared inside the `{ .. }` block, and as of **ES6** is block-scoped there. So it's not available outside that block. But also note that it is "hoisted" within the block, as opposed to `let` declarations, which suffer the TDZ error trap mentioned earlier.

Block-scoping of function declarations could be a problem if you've ever written code like this before, and relied on the old legacy non-block-scoped behavior:

```js
if (true) {
  function hamed() {
    console.log("1");
  }
}
else {
  function hamed() {
    console.log("2");
  }
}

hamed(); // "1"
```

In pre-**ES6** environments, `hamed()` would print `"2"` regardless of the value of `true` (or other conditions), because both function declarations were hoisted out of the blocks, and the second one always wins.

In **ES6**, that last line throws a `ReferenceError` (if use `strict`).

## Spread/Rest

**ES6** introduces a new `...` operator that's typically referred to as the spread or rest operator, depending on where/how it's used. Let's take a look:

```js
function hamid(a, b, c) {
  console.log(a + b + c);
}

hamid(...[21, 22, 23]); // 66
```

When `...` is used in front of an array (actually, any iterable) it acts to **spread** it out into its individual values.

You'll typically see that usage as is shown in that previous snippet, when spreading out an array as a set of arguments to a function call. In this usage, `...` acts to give us a simpler syntactic replacement for the `apply()` method, which we would typically have used pre-**ES6** as:

```js
hamid.apply(null, [21, 22, 23]); // 66
```

But `...` can be used to spread out/expand a value in other contexts as well, such as inside another array declaration:

```js
let hamed = [2, 3, 4];
let hamid = [1, ...hamed, 5];
console.log(hamid); // [ 1, 2, 3, 4, 5 ]
```

In this usage, `...` is basically replacing `concat(..)` , as it behaves like `[1].concat(hamed, [5])` here.

The other common usage of `...` can be seen as essentially the opposite; instead of spreading a value out, the `...` gathers a set of values together into an array. Consider:

```js
function hamed(a, b, ...c) {
  console.log(a, b, c);
}

hamed(1, 2, 3, 4, 5, 6, 7, 8); // 1 2 [ 3, 4, 5, 6, 7, 8 ]
```

The `...c` in this snippet is essentially saying: "gather the rest of the arguments (if any) into an array called `c`". Because `a` was assigned `1`, and `b` was assigned `2`, the rest of the arguments `3`, `4`, `5`, `6`, `7` and `8` were gathered into `c`.

Of course, if you don't have any named parameters, the `...` gathers all arguments:

```js
function hamid(...args) {
  console.log(args);
}

hamid(1, 2, 3, 4, 5, 6, 7, 8); // [ 1, 2, 3, 4, 5, 6, 7, 8 ]
```

**Note**: The `...args` in the `hamid(..)` function declaration is usually called **rest parameters**, because you're collecting the rest of the parameters. We prefer **gather**, because it's more descriptive of what it does rather than what it contains.

## Default Parameter Values

Perhaps one of the most common idioms in **JavaScript** relates to setting a default value for a function parameter. The way we've done this for years should look quite familiar:

```js
function defaultValue(a, b) {
  a = a || 15;
  b = b || 8;
  console.log(a + b);
}

defaultValue(); // 23
defaultValue(3, 7); // 10
defaultValue(3); // 11
defaultValue(null, 7); // 22
```

Of course, if you've used this pattern before, you know that it's both helpful and a little bit dangerous, if for example you need to be able to pass in what would otherwise be considered a falsy value for one of the parameters. Consider:

```js
defaultValue(0, 7); // 22
```

Why answer is `22`? Because the `0` is falsy, and so the `a || 15` results in `15`, not the directly passed in `0`.

To fix this gotcha, some people will instead write the check more verbosely like this:

```js
function defaultValue(a, b) {
  a = (a !== undefined) ? a : 15;
  b = (b !== undefined) ? b : 8;
  console.log(a + b);
}

defaultValue(0, 23); // 23
defaultValue(undefined, 23); // 38
```

Of course, that means that any value except `undefined` can be directly passed in. However, `undefined` will be assumed to signal, "**I** didn't pass this in". That works great unless you actually need to be able to pass `undefined` in.

In that case, you could test to see if the argument is actually omitted, by it actually not being present in the `arguments`, array, perhaps like this:

```js
function defaultValue(a, b) {
  a = (0 in arguments) ? a : 11;
  b = (1 in arguments) ? b : 31; // NaN
  console.log(a + b);
}

defaultValue(4); // 35
defaultValue(4, undefined); // NaN
```

But how would you omit the first `a` argument without the ability to pass in any kind of value (not even `undefined`) that signals **I'm omitting this argument**?

`defaultValue(, 4)` is tempting, but it's invalid syntax. `defaultValue.apply(null,[, 4])` seems like it should do the trick, but `apply(..)`'s quirks here mean that the arguments are treated as `[undefined, 4]`, which of course doesn't omit.

We can now examine a nice helpful syntax added as of **ES6** to streamline the assignment of default values to missing arguments:

```js
function defaultValue(a = 15, b = 8) {
  console.log(a + b);
}

defaultValue(); // 23
defaultValue(3, 7); // 10
defaultValue(0, 23); // 23
console.log("-----");
defaultValue(3); // 11
defaultValue(3, undefined); // 11
defaultValue(3, null); // 3
console.log("-----");
defaultValue(undefined, 7); // 22
```

Notice the results and how they imply both subtle differences and similarities to the earlier approaches.

`a = 15` in a function declaration is more like `a !== undefined ? a : 15` than the much more common idiom `a || 15`, so you'll need to be careful in converting your pre-**ES6** code to this **ES6** default parameter value syntax.

**Note**: A rest/gather parameter (see **Spread/Rest**) cannot have a default value. So, while `function defaultValue(...vals=[1,2,3]) {` might seem an intriguing capability, it's not valid syntax. You'll need to continue to apply that sort of logic manually if necessary.

## Default Value Expressions

Function default values can be more than just simple values like `8`; they can be any valid expression, even a function call:

```js
let hamid = 23;

function hamed(a = hamid) {
  return a;
}

function ali(a = hamed(), b = (45 + hamid)) {
  console.log(a, b);
}

ali(); // 23 68
```

As you can see, the default value expressions are lazily evaluated, meaning they're only run if and when they're needed -- that is, when a parameter's argument is omitted or is `undefined`.

Look below code:

```js
let w = 1, z = 2;
function hamed(x = w + 1, y = x + 1, z = z + 1) {
  console.log(x, y, z);
}

hamed(); // ReferenceError: Cannot access 'z' before initialization
```

The `w` in the `w + 1` default value expression looks for `w` in the formal parameters' scope, but does not find it, so the outer scope's `w` is used. Next, The `x` in the `x + 1` default value expression finds `x` in the formal parameters' scope, and luckily `x` has already been initialized, so the assignment to `y` works fine.

However, the `z`  in `z + 1` finds `z` as a not-yet-initialized-at-that-moment parameter variable, so it never tries to find the `z` from the outer scope.

As we mentioned in the **`let` Declaration** section earlier in this chapter, **ES6** has a TDZ, which prevents a variable from being accessed in its uninitialized state. As such, the `z + 1` default value expression throws a TDZ `ReferenceError` error.

Though it's not necessarily a good idea for code clarity, a default value expression can even be an inline function expression call -- commonly referred to as an immediately invoked function expression (IIFE):

```js
function hamid(a =
  (function (v) { return v + 15; })(8)
) {
  console.log(a);
}

hamid(); // 23
```

There will very rarely be any cases where an IIFE (or any other executed inline function expression) will be appropriate for default value expressions. If you find yourself tempted to do this, take a step back and reevaluate!

**Warning**: If the IIFE had tried to access the `a` identifier and had not declared its own `a`. this would also have been a TDZ error, just as discussed before.

## Destructuring

**ES6** introduces a new syntactic feature called destructuring, which may be a little less confusing if you instead think of it as structured assignment. To understand this meaning, consider:

```js
function hamed() {
  return [1, 2, 3];
}

let temp = hamed(),
  a = temp[0], b = temp[1], c = temp[2];

console.log(a, b, c); // 1 2 3
```

As you can see, we created a manual assignment of the values in the array that `hamed()` returns to individual variables `a`, `b` and `c`, and to do so we (unfortunately) needed the `temp` variable.

Similarly, we can do the following with objects:

```js
function hamid() {
  return {
    x: 4,
    y: 5,
    z: 6
  }
}

let temp = hamid(),
  x = temp.x, y = temp.y, z = temp.z;

console.log(x, y, z); // 4 5 6
```

The `temp.x` property value is assigned to the `x` variable, and likewise for `temp.y` to `y` and `temp.z` to `z`.

Manually assigning indexed values from an array or properties from an object can be thought of as structured assignment. **ES6** adds a dedicated syntax for destructuring, specifically array destructuring and object destructuring. This syntax eliminates the need for the `temp` variable in the previous snippets, making them much cleaner. Consider:

```js
let [a, b, c] = hamed();
console.log(a, b, c); // 1 2 3 | SyntaxError: Identifier 'a' has already been declared

let { x: x, y: y, z: z } = hamid();
console.log(x, y, z); // 4 5 6 | SyntaxError: Identifier 'a' has already been declared
```

You're likely more accustomed to seeing syntax like `[a,b,c]` on the righthand side of an `=` assignment, as the value being assigned.

Destructuring symmetrically flips that pattern, so that `[a,b,c]` on the lefthand side of the `=` assignment is treated as a kind of **pattern** for decomposing the righthand side array value into separate variable assignments.

```js
let { x, y, z } = hamid();
console.log(x, y, z); // 4 5 6
```

Pretty cool, isn't it?

But is `{ x, .. }` leaving off the `x:` part or leaving off the`: x` part? We're actually leaving off the `x:` part when we use the shorter syntax. That may not seem like an important detail, but you'll understand its importance in just a moment.

If you can write the shorter form, why would you ever write out the longer form? Because that longer form actually allows you to assign a property to a different variable name, which can sometimes be quite useful:

```js
let { x: bam, y: pam, z: jam } = hamid();
console.log(bam, pam, jam); // 4 5 6
console.log( x, y, z ); // 4 5 6 (ReferenceError in some browser)
```

There's a subtle but super-important quirk to understand about this variation of the object destructuring form. To illustrate why it can be a gotcha you need to be careful of, let's consider the **pattern** of how normal object literals are specified:

```js
let X = 10, Y = 20;
let o = { a: X, b: Y };
console.log(o.a, o.b); // 10 20
```

In `{ a: X, b: Y }`, we know that `a` is the object property, and `X` is the source value that gets assigned to it. In other words, the syntactic pattern is `target: source`, or more obviously, `property-alias: value`. We intuitively understand this because it's the same as `=` assignment, where the pattern is `target = source`.

However, when you use object destructuring assignment -- that is, putting the `{ .. }` object literal-looking syntax on the lefthand side of the `=` operator -- you invert that `target: source` pattern.

Recall:

```js
let { x: bam, y: pam, z: jam } = hamid();
```

The syntactic pattern here is `source: target` (or `value: variable-alias`). `x: bam` means the `x` property is the source value and `bam` is the target variable to assign to. In other words, object literals are `target <-- source`, and object destructuring assignments are `source --> target`. See how that's flipped?

There's another way to think about this syntax though, which may help ease the confusion. Consider:

```js
let aa = 10, bb = 20;
let o = { x: aa, y: bb };
let { x: AA, y: BB } = o;
console.log(aa, bb); // 10 20
console.log(AA, BB); // 10 20
```

In the `{ x: aa, y: bb }` line, the `x` and `y` represent the object properties. In the `{ x: AA, y: BB }` line, the `x` and the `y` also represent the object properties.

Recall how earlier we asserted that `{ x, .. }` was leaving off the `x:` part? In those two lines, if you erase the `x:` and `y:` parts in that snippet, you're left only with `aa, bb` and `AA, BB`, which in effect -- only conceptually, not actually -- are assignments from `aa` to `AA` and from `bb` to `BB`.

So, that symmetry may help to explain why the syntactic pattern was intentionally flipped for this **ES6** feature.

**Note**: We would have preferred the syntax to be `{ AA: x , BB: y }` for the destructuring assignment, as that would have preserved consistency of the more familiar `target: source` pattern for both usages. Alas, we having to train our brain for the inversion, as some readers may also have to do.

---

So far, we've used destructuring assignment with `let` declarations (of course, they could also use `var` and `const`), but destructuring is a general assignment operation, not just a declaration. Consider:

```js
let a, b, c, x, y, z;
[a, b, c] = hamed();
({ x, y, z } = hamid());
console.log(a, b, c); // 1 2 3
console.log(x, y, z); // 4 5 6
```

The variables can already be declared, and then the destructuring only does assignments (make TypeError error happened), exactly as we've already seen.

**Note**: For the object destructuring form specifically, when leaving off a `var` | `let` | `const` declarator, we had to surround the whole assignment expression in `()`, because otherwise the `{ .. }` on the lefthand side as the first element in the statement is taken to be a block statement instead of an object.

In fact, the assignment expressions (`a`, `y` and etc.) don't actually need to be just variable identifiers. Anything that's a valid assignment expression is allowed. For example:

```js
let o = {};
[o.a, o.b, o.c] = hamed();
({ x: o.x, y: o.y, z: o.z } = hamid());
console.log(o.a, o.b, o.c); // 1 2 3
console.log(o.x, o.y, o.z); // 4 5 6
```

You can even use computed property expressions in the destructuring. Consider:

```js
let which = "x",
  o = {};
({ [which]: o[which] } = hamid());
console.log(o.x); // 4
```

The `[which]:` part is the computed property, which results in `x` -- the property to destructure from the object in question as the source of the assignment. The `o[which]` part is just a normal object key reference, which equates to `o.x` as the target of the assignment.

You can use the general assignments to create object mappings/transformations, such as copy-paste:

```js
let o1 = { a: 1, b: 2, c: 3 },
  o2 = {};
({ a: o2.x, b: o2.y, c: o2.z } = o1);
console.log(o2.x, o2.y, o2.z); // 1 2 3
```

Or you can map an object to an array, such as:

```js
let o1 = { a: 1, b: 2, c: 3 },
  a2 = [];
({ a: a2[0], b: a2[1], c: a2[2] } = o1);
console.log(a2); // [ 1, 2, 3 ]
```

Or the other way around:

```js
let a1 = [1, 2, 3],
  o2 = {};
[o2.a, o2.b, o2.c] = a1;
console.log(o2.a, o2.b, o2.c); // 1 2 3
```

Or you could reorder one array to another:

```js
let a1 = [1, 2, 3],
  a2 = [];
[a2[2], a2[0], a2[1]] = a1;
console.log(a2); // [ 2, 3, 1 ]
```

You can even solve the traditional **swap two variables** task without a temporary variable:

```js
let x = 10, y = 20;
[y, x] = [x, y];
console.log(x, y); // 20 10
```

**Warning**: Be careful: you shouldn't mix in declaration with assignment unless you want all of the assignment expressions also to be treated as declarations. Otherwise, you'll get syntax errors. That's why in the earlier example we had to do `let a2 = []` separately from the `[a2[0], .. ] = ..` destructuring assignment. It wouldn't make any sense to try `let [ a2[0], .. ] = ..`, because `a2[0]` isn't a valid declaration identifier; it also obviously couldn't implicitly create a `let a2 = []` declaration to use.

## Repeated Assignments

The object destructuring form allows a source property (holding any value type) to be listed multiple times. For example:

```js
let { a: X, a: Y } = { a: 23 };
console.log(X); // 23
console.log(Y); // 23
```

That also means you can both destructure a sub-object/array property and also capture the sub-object/array's value itself. Consider:

```js
let { a: { x: X, x: Y }, a } = { a: { x: 23 } };
console.log(X); // 23
console.log(Y); // 23
console.log(a); // { x: 23 }

({ a: X, a: Y, a: [Z] } = { a: [23] });

X.push(2);
Y[0] = 10;

console.log(X); // [ 10, 2 ]
console.log(Y); // [ 10, 2 ]
console.log(Z); // 23
```

**A word of caution about destructuring**: it may be tempting to list destructuring assignments all on a single line as has been done thus far in our discussion. However, it's a much better idea to spread destructuring assignment patterns over multiple lines, using proper indentation -- much like you would in JSON or with an object literal value -- for readability sake.

```js
// harder to read:
let { a: { b: [c, d], e: { f } }, g } = obj;

// better:
let {
  a: {
    b: [c, d],
    e: { f }
  },
  g
} = obj;
```

**Remember: the purpose of destructuring is not just less typing, but more declarative readability**.

## Destructuring Assignment Expressions

The assignment expression with object or array destructuring has as its completion value the full righthand object/array value. Consider:

```js
let o = { a: 1, b: 2, c: 3 },
  a, b, c, d;

d = { a, b, c } = o;

console.log(a, b, c); // 1 2 3
console.log(d === o); // true
```

In the previous snippet, `d` was assigned the `o` object reference, not one of the `a`, `b` or `c` values. The same is true of array destructuring:

```js
let o = [1, 2, 3],
  a, b, c, d;

d = [a, b, c] = o;

console.log(a, b, c); // 1 2 3
console.log(d === o); // true
```

By carrying the object/array value through as the completion, you can chain destructuring assignment expressions together:

```js
let o = { a: 1, b: 2, c: 3 },
  d = [4, 5, 6],
  a, b, c, x, y, z;
({ a } = { b, c } = o);
[x, y] = [z] = d;
console.log(a, b, c); // 1 2 3
console.log(x, y, z); // 4 5 4
```

With both array destructuring assignment and object destructuring assignment, you do not have to assign all the values that are present. For example:

```js
let [, b] = hamed();
let { x, z } = hamid();
console.log(b, x, z); // 2 4 6
```

The `1` and `3` values that came back from `hamed()` are discarded, as is the `5` value from `hamid()`.

Similarly, if you try to assign more values than are present in the value you're destructuring/decomposing, you get graceful fallback to `undefined`, as you'd expect:

```js
let [, , c, d] = hamed();
let { w, z } = hamid();
console.log(c, z); // 3 6
console.log(d, w); // undefined undefined
```

This behavior follows symmetrically from the earlier stated **`undefined` is missing** principle.

We examined the `...` operator earlier in this chapter, and saw that it can sometimes be used to spread an array value out into its separate values, and sometimes it can be used to do the opposite: **to gather a set of values together into an array**.

In addition to the gather/rest usage in function declarations, `...` can perform the same behavior in destructuring assignments. To illustrate, let's recall a snippet from earlier in this chapter:

```js
let a = [2, 3, 4];
let b = [1, ...a, 5];
console.log(b); // [ 1, 2, 3, 4, 5 ]
```

Here we see that `...a` is spreading `a` out, because it appears in the array `[ .. ]` value position. If `...a` appears in an array destructuring position, it performs the gather behavior:

```js
let a = [2, 3, 4];
let [b, ...c] = a;
console.log(b, c); // 2 [ 3, 4 ]
```

The `var [ .. ] = a` destructuring assignment spreads `a` out to be assigned to the pattern described inside the `[ .. ]`. The first part names `b` for the first value in `a` (`2`). But then `...c` gathers the rest of the values (`3` and `4`) into an array and calls it `c`.

**Note**: We've seen how `...` works with arrays, but what about with objects? It's not an **ES6** feature, but see later for discussion of a possible "beyond **ES6**" feature where `...` works with spreading or gathering objects.

```js
let [a = 3, b = 6, c = 9, d = 12] = hamed();
let { x = 5, y = 10, z = 15, w = 20 } = hamid();
console.log(a, b, c, d); // 1 2 3 12
console.log(x, y, z, w); // 4 5 6 20
```

## Default Value Assignment

Both forms of destructuring can offer a default value option for an assignment, using the `=` syntax similar to the default function argument values discussed earlier. Consider:

```js
let [a = 3, b = 6, c = 9, d = 12] = hamed();
let { x = 5, y = 10, z = 15, w = 20 } = hamid();
console.log(a, b, c, d); // 1 2 3 12
console.log(x, y, z, w); // 4 5 6 20
```

You can combine the default value assignment with the alternative assignment expression syntax covered earlier. For example:

```js
let { x, y, z, w: WW = 20 } = hamid();
console.log(x, y, z, WW); // 4 5 6 20
```

Be careful about confusing yourself (or other developers who read your code) if you use an object or array as the default value in a destructuring. You can create some really hard to understand code:

```js
let x = 200, y = 300, z = 100;
let o1 = { x: { y: 23 }, z: { y: z } };
console.log(({ y: x = { y: y } } = o1)); // { x: { y: 23 }, z: { y: 100 } }
console.log(({ z: y = { y: z } } = o1)); // { x: { y: 23 }, z: { y: 100 } }
console.log(({ x: z = { y: x } } = o1)); // { x: { y: 23 }, z: { y: 100 } }
```

Can you tell from that snippet what values `x`, `y` and `z` have at the end? Takes a moment of pondering, We would imagine. we'll end the suspense:

```js
console.log(x.y, y.y, z.y); // 300 100 23
```

**The takeaway here**: Destructuring is great and can be very useful, but it's also a **sharp sword** that can cause injury (to someone's brain) if used unwisely.

## Nested Destructuring

If the values you're destructuring have nested objects or arrays, you can destructure those nested values as well:

```js
let a1 = [1, [2, 3, 4], 5];
let o1 = { x: { y: { z: 6 } } };
let [a, [b, c, d], e] = a1;
let { x: { y: { z: w } } } = o1;
console.log(a, b, c, d, e); // 1 2 3 4 5
console.log(w); // 6
```

Nested destructuring can be a simple way to flatten out object namespaces. For example:

```js
let App = {
  model: {
    User: function () { }
  }
};
// instead of: let User = App.model.User;

let { model: { User } } = App;
```

## Destructuring Parameters

In the following snippet, can you spot the assignment?

```js
function hamed(x) {
  console.log(x);
}

hamed(23); // 23
```

The assignment is kinda hidden: `23` (the argument) is assigned to `x` (the parameter) when `hamed(23)` is executed. If parameter/argument pairing is an assignment, then it stands to reason that it's an assignment that could be destructured, right? Of course!

Consider array destructuring for parameters:

```js
function hamid([x, y]) {
  console.log(x, y);
}

hamid([1, 2]); // 1 2
hamid([1]); // 1 undefined
hamid([]); // undefined undefined
```

Object destructuring for parameters works, too:

```js
function ali({ x, y }) {
  console.log(x, y);
}

ali({ y: 1, x: 2 }); // 2 1
ali({ y: 23 }); // undefined 23
ali({}); // undefined undefined
```

This technique is an approximation of named arguments (a long requested feature for **JavaScript**), in that the properties on the object map to the destructured parameters of the same names. That also means that we get optional parameters (in any position) for free, as you can see leaving off the `x` **parameter** worked as we'd expect.

Of course, all the previously discussed variations of destructuring are available to us with parameter destructuring, including nested destructuring, default values, and more. Destructuring also mixes fine with other **ES6** function parameter capabilities, like default parameter values and rest/gather parameters.

Some example are here:

```js
function f1([ x=2, y=3, z ]) { .. }
function f2([ x, y, ...z], w) { .. }
function f3([ x, y, ...z], ...w) { .. }
function f4({ x: X, y }) { .. }
function f5({ x: X = 10, y = 20 }) { .. }
function f6({ x = 10 } = {}, { y } = { y: 10 }) { .. }
```

Let's take one example (f3 as reza) from this snippet and examine it, for illustration purposes:

```js
function reza([x, y, ...z], ...w) {
  console.log(x, y, z, w);
}

reza([]); // undefined undefined [] []
reza([1, 2, 3, 4], 5, 6); // 1 2 [ 3, 4 ] [ 5, 6 ]
```

There are two `...` operators in use here, and they're both gathering values in arrays (`z` and `w`), though `...z` gathers from the rest of the values left over in the first array argument, while `...w` gathers from the rest of the main arguments left over after the first.

There's one subtle point you should be particularly careful to notice -- the difference in behavior between a destructuring default value and a function parameter default value. For example:

```js
// f6 as majid
function majid({ x = 10 } = {}, { y } = { y: 10 }) {
  console.log(x, y);
}

majid(); // 10 10
```

At first, it would seem that we've declared a default value of `10` for both the `x` and `y` parameters, but in two different ways. However, these two different approaches will behave differently in certain cases, and the difference is awfully subtle. Consider:

```js
majid({}, {}); // 10 undefined
```

Wait, why did that happen? It's pretty clear that named parameter `x` is defaulting to `10` if not passed as a property of that same name in the first argument's object.

But what about `y` being `undefined`? The `{ y: 10 }` value is an object as a function parameter default value, not a destructuring default value. As such, it only applies if the second argument is not passed at all, or is passed as `undefined`.

In the previous snippet, we are passing a second argument (`{}`), so the default `{ y: 10 }` value is not used, and the `{ y }` destructuring occurs against the passed in `{}` empty object value.

Now, compare `y } = { y: 10 }`to `{ x = 10 } = {}`.

For the `x`'s form usage, if the first function argument is omitted or `undefined`, the `{}` empty object default applies. Then, whatever value is in the first argument position -- either the default `{}` or whatever you passed in -- is destructured with the `{ x = 10 }`, which checks to see if an `x` property is found, and if not found (or `undefined`), the`10` default value is applied to the `x` named parameter. Let's review previous code with more outputs:

```js
// f6 as majid
function majid({ x = 10 } = {}, { y } = { y: 10 }) {
  console.log(x, y);
}

majid(); // 10 10
majid(undefined, undefined); // 10 10
majid({}, undefined); // 10 10
majid({}, {}); // 10 undefined
majid(undefined, {}); // 10 undefined
majid({ x: 2 }, { y: 3 }); // 2 3
```

It would generally seem that the defaulting behavior of the `x` parameter is probably the more desirable and sensible case compared to that of `y`. As such, it's important to understand why and how `{ x = 10 } = {}` form is different from `{ y } = { y: 10 }` form.

If that's still a bit fuzzy, go back and read it again, and play with this yourself. Your future self will thank you for taking the time to get this very subtle gotcha nuance detail straight.

---

## Object Literal Extensions

**ES6** adds a number of important convenience extensions to the humble `{ .. }` object literal.

## Concise Properties

You're certainly familiar with declaring object literals in this form:

```js
let x = 1, y = 2,
  o = {
    x: x,
    y: y
  };

console.log(o); // { x: 1, y: 2 }
```

If it's always felt redundant to say `x:x` all over, there's good news. If you need to define a property that is the same name as a lexical identifier, you can shorten it from `x:x` to `x`.

```js
let x = 1, y = 2,
  o = {
    x,
    y
  };

console.log(o); // { x: 1, y: 2 }
```

## Concise Methods

In a similar spirit to concise properties we just examined, functions attached to properties in object literals also have a concise form, for convenience.

The old way:

```js
let o = {
  x: function () {
    // do something
  },
  y: function () {
    // do something
  }
};
```

And as of **ES6**:

```js
let o = {
  x() {
    // do something
  },
  y() {
    // do something
  }
};
```

**Warning**: While `x() { .. }` seems to just be shorthand for `x: function(){ .. }`, concise methods have special behaviors that their older counterparts don't; specifically, the allowance for `super`.

Generators also have a concise method form:

```js
let o = {
  *x() { .. }
  };
```

That's actually a pretty common practice when the object literal does have an identifying name, such as:

```js
let controller = {
  makeRequest: function () {
    // do something
    controller.makeRequest();
  }
};
```

Is this a good idea? Perhaps, perhaps not. You're assuming that the name `controller` will always point to the object in question. But it very well may not -- the `makeRequest(..)` function doesn't control the outer code and so can't force that to be the case. **This could come back to bite you**.

Others prefer to use `this` to define such things:

```js
let controller = {
  makeRequest: function () {
    // do something
    this.makeRequest();
  }
};
```

That looks fine, and should work if you always invoke the method as `controller.makeRequest(..)`. But you now have a `this` binding gotcha if you do something like:

```js
btn.addEventListener("click", controller.makeRequest, false);
```

Of course, you can solve that by passing `controller.makeRequest.bind(controller)` as the handler reference to bind the event to. But yuck -- it isn't very appealing.

Or what if your inner `this.makeRequest(..)` call needs to be made from a nested function? You'll have another `this` binding hazard, which people will often solve with the hacky `var self = this`, such as:

```js
let controller = {
  makeRequest: function () {
    var self = this;
    btn.addEventListener("click", function () {
      // ..
      self.makeRequest();
    }, false);
  }
};
```

More yuck!

## ES5 Getter/Setter

Technically, **ES5** defined getter/setter literals forms, but they didn't seem to get used much, mostly due to the lack of transpilers to handle that new syntax (the only major new syntax added in **ES5**, really). So while it's not a new **ES6** feature, we'll briefly refresh on that form, as it's probably going to be much more useful with **ES6** going forward. Consider:

```js
let o = {
  __id: 10,
  get id() { return this.__id++; },
  set id(v) { this.__id = v; }
}

console.log(o.id); // 10
console.log(o.id); // 11

o.id = 20;
console.log(o.id); // 20

// and:
console.log(o.__id); // 21
console.log(o.__id); // 21 -- still!
```

These getter and setter literal forms are also present in classes.

Warning: It may not be obvious, but the setter literal must have exactly one declared parameter; omitting it or listing others is illegal syntax. The single required parameter can use destructuring and defaults (e.g., `set id({ id: v = 0 }) { .. }`), but the gather/rest `...` is not allowed (`set id(...v) { .. }`).

## Computed Property Names

You've probably been in a situation like the following snippet, where you have one or more property names that come from some sort of expression and thus can't be put into the object literal:

```js
let prefix = "user_";

let o = {
  ali: function () { /* do something */ }
};

o[prefix + "hamed"] = function () { /* do something */ };
o[prefix + "hamid"] = function () { /* do something */ };
...
```

**ES6** adds a syntax to the object literal definition which allows you to specify an expression that should be computed, whose result is the property name assigned. Consider:

```js
let prefix = "user_";

let o = {
  ali: function () { /* do something */ },
  [prefix + "hamed"]: function () { /* do something */ },
  [prefix + "hamid"]: function () { /* do something */ }
  ...
};
```

Any valid expression can appear inside the `[ .. ]` that sits in the property name position of the object literal definition.

Probably the most common use of computed property names will be with `Symbol`s  (which we cover in **Symbols** later in this chapter), such as:

```js
let o = {
  [Symbol.toStringTag]: "Hello guys",
  ...
};
```

`Symbol.toStringTag` is a special built-in value, which we evaluate with the `[ .. ]` syntax, so we can assign the `"Hello guys"` value to the special property name.

Computed property names can also appear as the name of a concise method or a concise generator:

```js
let o = {
  ["ha" + "med"]() { /* do something */ }, // computed concise method
  *["ha" + "mid"]() { /* do something */ } // computed concise generator
};
```

## Setting [[Prototype]]

We won't cover prototypes in detail here, so for more information, see the **this-example** and **object-example** files.

Sometimes it will be helpful to assign the `[[Prototype]]` of an object at the same time you're declaring its object literal. The following has been a nonstandard extension in many **JavaScript** engines for a while, but is standardized as of **ES6**:

```js
let o1 = {
  // do something
};

let o2 = {
  __proto__: o1,
  // do something
};
```

`o2` is declared with a normal object literal, but it's also `[[Prototype]]`-linked to `o1`.The `__proto__` property name here can also be a string `"__proto__"`, but note that it cannot be the result of a computed property name (see the previous section).

`__proto__` is controversial, to say the least. It's a decades-old proprietary extension to **JavaScript** that is finally standardized, somewhat begrudgingly it seems, in **ES6**. Many developers feel it shouldn't ever be used. In fact, **JavaScript** feels it has to standardize for compatibility reasons only.

**Warning**: Though we narrowly endorsing `__proto__` as a key in an object literal definition, We definitely do not endorse using it in its object property form, like `o.__proto__`. That form is both a getter and setter (again for compatibility reasons), but there are definitely better options. See the **this-example** and **object-example** files for more information.

For setting the `[[Prototype]]` of an existing object, you can use the **ES6** utility `Object.setPrototypeOf(..)`. Consider:

```js
let o1 = {
  // do something
};

let o2 = {
  // do something
}

Object.setPrototypeOf(o2, o1);
```

**Note**: We'll discuss `Object` again later. **`Object.setPrototypeOf(..)` Static Function** provides additional details on `Object.setPrototypeOf(..)`.

## Object `super`

`super` is typically thought of as being only related to classes. However, due to **JavaScript**'s classless-objects-with-prototypes nature, `super` is is equally effective, and nearly the same in behavior, with plain objects' concise methods. Consider:

```js
let o1 = {
  hamed() {
    console.log("o1:hamed");
  }
};

let o2 = {
  hamed() {
    super.hamed();
    console.log("o2:hamed");
  }
};

Object.setPrototypeOf(o2, o1);

console.log(o2.hamed()); // "o1:hamed" "o2:hamed"
```

**Warning**: `super` is only allowed in concise methods, not regular function expression properties. It also is only allowed in `super.XXX` form (for property/method access), not in `super()` form.

The `super` reference in the `o2.hamed()` method is locked statically to `o2`, and specifically to the `[[Prototype]]` of `o2`.`super` here would basically be `Object.getPrototypeOf(o2)` -- resolves to `o1` of course -- which is how it finds and calls `o1.hamed()`.

## Template Literals

At the very outset of this section, we going to have to call out the name of this **ES6** feature as being awfully... misleading, depending on your experiences with what the word template means.

Many developers think of templates as being reusable renderable pieces of text, such as the capability provided by most template engines (Mustache, Handlebars, etc.). **ES6**'s use of the word template would imply something similar, like a way to declare inline template literals that can be re-rendered. However, that's not at all the right way to think about this feature.

So, before we go on, we renaming to what it should have been called: **interpolated string literals** (or interpoliterals for short).

You're already well aware of declaring string literals with `"` or `'` delimiters, and you also know that these are not smart strings (as some languages have), where the contents would be parsed for interpolation expressions.

However, **ES6** introduces a new type of string literal, using the `` ` `` backtick as the delimiter. These string literals allow basic string interpolation expressions to be embedded, which are then automatically parsed and evaluated.

Here's the old pre-**ES6** way:

```js
let name = "Hamid";
let greeting = "Hello " + name + "!";
console.log(greeting); // "Hello Hamid!"
console.log(typeof greeting); // "string"
```

Now, consider the new **ES6** way:

```js
let name = "Hamid";
let greeting = `Hello ${name}!`;
console.log(greeting); // "Hello Hamid!"
console.log(typeof greeting); // "string"
```

As you can see, we used the `` `..` `` around a series of characters, which are interpreted as a string literal, but any expressions of the form `${..}` are parsed and evaluated inline immediately. The fancy term for such parsing and evaluating is interpolation (much more accurate than templating).

The result of the interpolated string literal expression is just a plain old normal string, assigned to the `greeting` variable.

**Warning**: `typeof greeting == "string"` illustrates why it's important not to think of these entities as special template values, as you cannot assign the unevaluated form of the literal to something and reuse it. The `` `..` `` string literal is more like an IIFE in the sense that it's automatically evaluated inline. The result of a `` `..` `` string literal is, simply, just a string.

One really nice benefit of **interpolated string literals** is they are allowed to split across multiple lines:

```js
let text =
  `Hello guys, wellcome to my page!
please help me to improve this page from this github link (address)`;

console.log(text);
```

The line breaks (newlines) in the interpolated string literal were preserved in the string value.

Unless appearing as explicit escape sequences in the literal value, the value of the `\r` carriage return character (code point `U+000D`) or the value of the `\r\n` carriage return + line feed sequence (code points `U+000D` and `U+000A`) are both normalized to a `\n` line feed character (code point `U+000A`). Don't worry though; this normalization is rare and would likely only happen if copy-pasting text into your **JavaScript** file.

## Interpolated Expressions

Any valid expression is allowed to appear inside `${..}` in an interpolated string literal, including function calls, inline function expression calls, and even other interpolated string literals! Consider:

```js
function toUpper(value) {
  return value.toUpperCase();
}

let org = "'nothing'";
let text = `Hello ${toUpper("hamed")}, wellcome your ${org}'s orginazition. Make it from "nothing" to "thing"`;

console.log(text); // Hello HAMED, wellcome your 'nothing' orginazition. Make it from "nothing" to "thing"
```

Here, the inner `` `${org}` `` interpolated string literal was a little bit nicer convenience for us when combining the `org` variable with the `"s"` string, as opposed to `org + "s"`. There will be cases that nesting interpolated string literals is helpful, but be wary if you find yourself doing that kind of thing often, or if you find yourself nesting several levels deep. If that's the case, the odds are good that your string value production could benefit from some abstractions.

**Warning**: As a word of caution, be very careful about the readability of your code with such new found power. Just like with default value expressions and destructuring assignment expressions, just because you can do something doesn't mean you should do it. Never go so overboard with new **ES6** tricks that your code becomes more clever than you or your other team members.

## Expression Scope

One quick note about the scope that is used to resolve variables in expressions. We mentioned earlier that an interpolated string literal is kind of like an IIFE, and it turns out thinking about it like that explains the scoping behavior as well. Consider:

```js
function hamed(str) {
  let name = "Hamed";
  console.log(str);
}

function hamid() {
  let name = "Hamid";
  hamed(`Hello my friend, ${name}`);
}

var name = "global";

hamid(); // Hello my friend, Hamid -- not "global" or "Hamed"
```

At the moment the `` `..` `` string literal is expressed, inside the `hamid()` function, the scope available to it finds `hamid()`'s `name` variable with value `"Hamid"`. Neither the global `name` nor `hamed(..)`'s `name` matter. In other words, an interpolated string literal is just lexically scoped where it appears, not dynamically scoped in any way.

## Tagged Template Literals

Again, renaming the feature for sanity sake: tagged string literals.

To be honest, this is one of the cooler tricks that **ES6** offers. It may seem a little strange, and perhaps not all that generally practical at first. But once you've spent some time with it, tagged string literals may just surprise you in their usefulness.

For example:

```js
function hamed(str, ...value) {
  console.log(str);
  console.log(value);
}

let info = "Cool";

hamed`Everything is ${info}!`;
/* output: [ 'Everything is ', '!' ]
[ 'Cool' ] */
```

Let's take a moment to consider what's happening in the previous snippet. First, the most jarring thing that jumps out is ``hamed`Everything...`;``. That doesn't look like anything we've seen before. What is it?

It's essentially a special kind of function call that doesn't need the `( .. )`. The tag -- the `hamed()` part before the `` `..` `` string literal -- is a function value that should be called. Actually, it can be any expression that results in a function, even a function call that returns another function, like:

```js
function hamid() {
  return function hamed(strs, ...values) {
    console.log(strs);
    console.log(values);
  }
}

let info = "Cool";

hamid()`Everything is ${info}!`;
/* output: [ 'Everything is ', '!' ]
[ 'Cool' ] */
```

**Q**: What gets passed to the `hamed(..)` function when invoked as a tag for a string literal?

**Answer**: The first argument -- we called it `strs` -- is an array of all the plain strings (the stuff between any interpolated expressions). We get two values in the `strs` array:

`"Everything is "` and `"!"`.

For convenience sake in our example, we then gather up all subsequent arguments into an array called `values` using the `...` gather/rest operator, though you could of course have left them as individual named parameters following the `strs` parameter.

There are many advanced ones that are beyond our scope to discuss here. But here's a simple idea that formats numbers as U.S. dollars (sort of like basic localization):

```js
function dollar(cost) {
  console.log(`This weapon costs $${cost}`);
}

dollar(49.99);
```

## Raw Strings

In the previous snippets, our tag functions receive the first argument we called `strs`, which is an array. But there's an additional bit of data included: the raw unprocessed versions of all the strings. You can access those raw string values using the `.row` property. like this:

```js
function rawShow(strs, ...values) {
  console.log(strs);
  console.log(strs.raw);
}

rawShow`Hello\n World`;
/* output: [ 'Hello\n World' ]
[ 'Hello\\n World' ]

or

/* output: [ 'Hello World' ]
[ 'Hello \n World' ] */
```

The raw version of the value preserves the raw escaped `\n` sequence (the `\` and the `n` are separate characters), while the processed version considers it a single newline character. However, the earlier mentioned line-ending normalization is applied to both values.

**ES6** comes with a built-in function that can be used as a string literal tag: `String.raw(..)`. It simply passes through the raw versions of the `strs` values:

```js
console.log(`Hello\nWorld`); // "Hello" \n "World"
console.log(String.raw`Hello\nWorld`); // "Hello\nWorld"
console.log(String.raw`Hello\nWorld`.length); // 12
```

Other uses for string literal tags included special processing for internationalization, localization, and more!

## Arrow Functions

We've touched on `this` binding complications with functions earlier in this chapter. It's important to understand the frustrations that `this`-based programming with normal functions brings, because that is the primary motivation for the new **ES6** `=>` arrow function feature.

Let's first illustrate what an arrow function looks like, as compared to normal functions:

```js
function hamed(x, y) {
  return x + y;
}

// versus

let hamid = (x, y) => x + y;

console.log(hamed(15, 8)); // 23
console.log(hamid(15, 8)); // 23
```

The arrow function definition consists of a parameter list (of zero or more parameters, and surrounding `( .. )` if there's not exactly one parameter), followed by the `=>` marker, followed by a function body.

So, in the previous snippet, the arrow function is just the `(x,y) => x + y` part, and that function reference happens to be assigned to the variable `hamid`.

The body only needs to be enclosed by `{ .. }` if there's more than one expression, or if the body consists of a non-expression statement. If there's only one expression, and you omit the surrounding `{ .. }`, there's an implied `return` in front of the expression, as illustrated in the previous snippet.

Here's some other arrow function variations to consider:

```js
let ali = () => 12;
let reza = x => x * 2;
let majid = (x, y) => {
  let z = x * 2 + y;
  y++;
  x *= 3;
  return (x + y + z) / 2;
};
```

Arrow functions are always function expressions; there is no arrow function declaration. It also should be clear that they are anonymous function expressions -- they have no named reference for the purposes of recursion or event binding/unbinding.

**Note**: All the capabilities of normal function parameters are available to arrow functions, including default values, destructuring, rest parameters, and so on.

Arrow functions have a nice, shorter syntax, which makes them on the surface very attractive for writing terser code. Indeed, nearly all literature on **ES6** seems to immediately and exclusively adopt the arrow function as **the new function**.

It is telling that nearly all examples in discussion of arrow functions are short single statement utilities, such as those passed as callbacks to various utilities. For example:

```js
let value = [1,2,3,4,5];
console.log(value.map(v => v * 2)); // [ 2, 4, 6, 8, 10 ]
```

In those cases, where you have such inline function expressions, and they fit the pattern of computing a quick calculation in a single statement and returning that result, arrow functions indeed look to be an attractive and lightweight alternative to the more verbose `function` keyword and syntax.

While not a hard-and-fast rule, we'd say that the readability gains from `=>` arrow function conversion are inversely proportional to the length of the function being converted. The longer the function, the less `=>` helps; the shorter the function, the more `=>` can shine.

We think it's probably more sensible and reasonable to adopt `=>` for the places in code where you do need short inline function expressions, but leave your normal-length main functions as is.

Most of the popular attention toward `=>` has been on saving those precious keystrokes by dropping `function`, `return`, and `{ .. }` from your code.

But there's a big detail we've skipped over so far. We said at the beginning of the section that `=>` functions are closely related to `this` binding behavior. In fact, `=>` arrow functions are primarily designed to alter `this` behavior in a specific way, solving a particular and common pain point with `this`-aware coding.

Let's revisit another example from earlier in this chapter:

```js
let controller = {
  makeRequest: function () {
    let self = this;
    btn.addEventListener("click", function () {
      // ..
      self.makeRequest();
    }, false);
  }
};
```

We used the `let self = this` hack, and then referenced `self.makeRequest(..)`, because inside the callback function we're passing to `addEventListener(..)`, the `this` binding will not be the same as it is in `makeRequest(..)` itself. In other words, because `this` bindings are dynamic, we fall back to the predictability of lexical scope via the `self` variable.

Herein we finally can see the primary design characteristic of `=>` arrow functions. Inside arrow functions, the `this` binding is not dynamic, but is instead lexical. In the previous snippet, if we used an arrow function for the callback, `this` will be predictably what we wanted it to be. Consider:

```js
let controller = {
  makeRequest: function () {
    btn.addEventListener("click", () => {
      // ..
      this.makeRequest();
    }, false);
  }
};
```

Lexical `this` in the arrow function callback in the previous snippet now points to the same value as in the enclosing `makeRequest(..)` function. In other words, `=>` is a syntactic stand-in for `let self = this`.

In cases where `let self = this` (or, alternatively, a function `.bind(this)` call) would normally be helpful, `=>` arrow functions are a nicer alternative operating on the same prinicple. Sounds great, right? Not quite so simple.

If `=>` replaces `let self = this` or `.bind(this)` and it helps, guess what happens if you use `=>` with a `this`-aware function that doesn't need `let self = this` to work? You might be able to guess that it's going to mess things up. Yeah.

Consider:

```js
let controller = {
  makeRequest: () => {
    // ..
    this.helper();
  },
  helper: () => {
    // ..
  }
};

controller.makeRequest();
```

Although we invoke as `controller.makeRequest(..)`, the `this.helper` reference fails, because `this` here doesn't point to `controller` as it normally would. Where does it point? It lexically inherits `this` from the surrounding scope. In this previous snippet, that's the global scope, where `this` points to the global object.

In addition to lexical `this`, arrow functions also have lexical `arguments` -- they don't have their own `arguments` array but instead inherit from their parent -- as well as lexical `super` and `new.target`.

So now we can conclude a more nuanced set of rules for when `=>` is appropriate and not:

- If you have a short, single-statement inline function expression, where the only statement is a `return` of some computed value, and that function doesn't already make a`this` reference inside it, and there's no self-reference (recursion, event binding/unbinding), and you don't reasonably expect the function to ever be that way, you can probably safely refactor it to be an `=>` arrow function.
- If you have an inner function expression that's relying on a `let self = this` hack or a `.bind(this)` call on it in the enclosing function to ensure proper `this` binding, that inner function expression can probably safely become an `=>` arrow function.
- If you have an inner function expression that's relying on something like `let args = Array.prototype.slice.call(arguments)` in the enclosing function to make a lexical copy of `arguments`, that inner function expression can probably safely become an `=>` arrow function.
- For everything else -- normal function declarations, longer multistatement function expressions, functions that need a lexical name identifier self-reference (recursion, etc.), and any other function that doesn't fit the previous characteristics -- you should probably avoid `=>` function syntax.

**Bottom line**: `=>` is about lexical binding of `this`, `arguments`, and `super`. These are intentional features designed to fix some common problems, not bugs, quirks, or mistakes in **ES6**.

Don't believe any hype that `=>` is primarily, or even mostly, about fewer keystrokes. Whether you save keystrokes or waste them, you should know exactly what you are intentionally doing with every character typed.

**Tip**: If you have a function that for any of these articulated reasons is not a good match for an `=>` arrow function, but it's being declared as part of an object literal, recall from **Concise Methods** earlier in this chapter that there's another option for shorter function syntax.

## `for..of` Loops

Joining the `for` and `for..in` loops from the **JavaScript** we're all familiar with, **ES6** adds a `for..of` loop, which loops over the set of values produced by an iterator.

The value you loop over with `for..of` must be an iterable, or it must be a value which can be coerced/boxed to an object that is an iterable. An iterable is simply an object that is able to produce an iterator, which the loop then uses.

Let's compare `for..of` to `for..in` to illustrate the difference:

```js
let array = ["a", "b", "c", "d"];

for (let idx in array) {
  console.log(idx); //  0 1 2 3
}

for (let val of array) {
  console.log(val); // "a" "b" "c" "d"
}
```

As you can see, `for..in` loops over the keys/indexes in the `array` array, while `for..of` loops over the values in `array`.

Here's the pre-**ES6** version of the `for..of` from that previous snippet:

```js
let array = ["a", "b", "c", "d", "e"],
  k = Object.keys(array);
for (let val, i = 0; i < k.length; i++) {
  val = array[k[i]];
  console.log(val); // "a" "b" "c" "d" "e"
}
```

And here's the **ES6** but non-`for..of` equivalent, which also gives a glimpse at manually iterating an iterator:

```js
let array = ["a", "b", "c", "d", "e"];
for (let val, ret, it = array[Symbol.iterator]();
  (ret = it.next()) && !ret.done;
) {
  val = ret.value;
  console.log(val); // "a" "b" "c" "d" "e"
}
```

Under the covers, the `for..of` loop asks the iterable for an iterator `Symbol.iterator`; then it repeatedly calls the iterator and assigns its produced value to the loop iteration variable.

Standard built-in values in **JavaScript** that are by default iterables (or provide them) include:

- Arrays
- Strings
- Gnerators
- Collections / TypedArrays

**Warning**: Plain objects are not by default suitable for `for..of` looping. That's because they don't have a default iterator, which is intentional, not a mistake. However, we won't go any further into those nuanced reasonings here.

Here's how to loop over the characters in a primitive string:

```js
let name = "Hamid";
for (let char of name) {
  console.log(char); // "H" "a" "m" "i" "d"
}
```

The `"Hamid"` primitive string value is coerced/boxed to the `String` object wrapper equivalent, which is an iterable by default.

In `for (XYZ of ABC)..`, the `XYZ` clause can either be an assignment expression or a declaration, identical to that same clause in `for` and `for..in` loops. So you can do stuff like this:

```js
let o = {};
for (o.a of [1, 2, 3]) {
  console.log(o.a); // 1 2 3
}

for ({ x: o.a } of [{ x: 1 }, { x: 2 }, { x: 3 }]) {
  console.log(o.a); // 1 2 3
}
```

`for..of` loops can be prematurely stopped, just like other loops, with `break`, `continue`, `return` (if in a function), and thrown exceptions. In any of these cases, the iterator's `return(..)` function is automatically called (if one exists) to let the iterator perform cleanup tasks, if necessary.

## Regular Expressions

Let's face it: regular expressions haven't changed much in **JavaScript** in a long time. So it's a great thing that they've finally learned a couple of new tricks in **ES6**. We'll briefly cover the additions here, but the overall topic of regular expressions is so dense that you'll need to turn to chapters/books dedicated to it (of which there are many!) if you need a refresher.

## Unicode Flag

We'll cover the topic of Unicode in more detail in **Unicode** later in this chapter. Here, we'll just look briefly at the new `u` flag for **ES6**+ regular expressions, which turns on Unicode matching for that expression.

**JavaScript** strings are typically interpreted as sequences of **16-bit** characters, which correspond to the characters in the **B**asic **M**ultilingual **P**lane (BMP).

Prior to **ES6**, regular expressions could only match based on BMP characters, which means that those extended characters were treated as two separate characters for matching purposes. This is often not ideal.

So, as of **ES6**, the `u` flag tells a regular expression to process a string with the interpretation of Unicode (UTF-16) characters, such that such an extended character will be matched as a single entity.

**Warning**: Despite the name implication, **UTF-16** doesn't strictly mean 16 bits. Modern Unicode uses 21 bits, and standards like UTF-8 and UTF-16 refer roughly to how many bits are used in the representation of a character.

An example (straight from the **ES6** specification): (the musical symbol G-clef) is Unicode point U+1D11E (0x1D11E).

If this character appears in a regular expression pattern (like `//`), the standard BMP interpretation would be that it's two separate characters (0xD834 and 0xDD1E) to match with. But the new **ES6** Unicode-aware mode means that `//u` (or the escaped Unicode form `/\u{1D11E}/u`) will match `""` in a string as a single matched character.

You might be wondering why this matters? In non-Unicode BMP mode, the pattern is treated as two separate characters, but would still find the match in a string with the `""` character in it, as you can see if you try:

```nothing
//.test("-clef"); // true
```

The length of the match is what matters. For example:

```js
/^.-clef/ .test( "-clef"); // false
/^.-clef/u.test( "-clef"); // true
```

The `^.-clef` in the pattern says to match only a single character at the beginning before the normal `"-clef"` text. In standard BMP mode, the match fails (two characters), but with `u` Unicode mode flagged on, the match succeeds (one character).

It's also important to note that `u` makes quantifiers like `+` and `*` apply to the entire Unicode code point as a single character, not just the lower surrogate (aka rightmost half of the symbol) of the character. The same goes for Unicode characters appearing in character classes, like `/[-]/u`.

## Sticky Flag

Another flag mode added to **ES6** regular expressions is `y`, which is often called "sticky mode". Sticky essentially means the regular expression has a virtual anchor at its beginning that keeps it rooted to matching at only the position indicated by the regular expression's `lastIndex` property.

To illustrate, let's consider two regular expressions, the first without sticky mode and the second with:

```js
let re1 = /hamed/,
  str = "++hamed++";

console.log(re1.lastIndex); // 0
console.log(re1.test(str)); // true
console.log(re1.lastIndex); // 0 -- not updated
console.log("-----");
re1.lastIndex = 4;
console.log(re1.test(str)); // true -- ignored `lastIndex`
console.log(re1.lastIndex); // 4 -- not updated
```

Three things to observe about this snippet:

- `test(..)` doesn't pay any attention to `lastIndex`'s value, and always just performs its match from the beginning of the input string.
- Because our pattern does not have a `^` start-of-input anchor, the search for `"hamed"` is free to move ahead through the whole string looking for a match.
- `lastIndex` is not updated by `test(..)`.

Now, let's try a sticky mode regular expression:

```js
let re2 = /hamid/y, // <-- notice the `y` sticky flag
  str = "++hamid++";

console.log(re2.lastIndex); // 0
console.log(re2.test(str)); // false -- "hamid" not found at `0`
console.log(re2.lastIndex); // 0
console.log("-----");
re2.lastIndex = 2;
console.log(re2.test(str)); // true
console.log(re2.lastIndex); // 7 -- updated to after previous match
console.log("-----");
console.log(re2.test(str)); // false
console.log(re2.lastIndex); // 0 -- reset after previous match failure
```

And so our new observations about sticky mode:

- `test(..)` uses `lastIndex` as the exact and only position in `str` to look to make a match. There is no moving ahead to look for the match -- it's either there at the `lastIndex` position or not.
- If a match is made, `test(..)` updates `lastIndex` to point to the character immediately following the match. If a match fails, `test(..)` resets `lastIndex` back to `0`.

Normal non-sticky patterns that aren't otherwise `^`-rooted to the start-of-input are free to move ahead in the input string looking for a match. But sticky mode restricts the pattern to matching just at the position of `lastIndex`.

As we suggested at the beginning of this section, another way of looking at this is that `y` implies a virtual anchor at the beginning of the pattern that is relative (aka constrains the start of the match) to exactly the `lastIndex` position.

**Warning**: In previous literature on the topic, it has alternatively been asserted that this behavior is like `y` implying a `^` (start-of-input) anchor in the pattern. This is inaccurate. We'll explain in further detail in **Anchored Sticky** later.

## Sticky Positioning

It may seem strangely limiting that to use `y` for repeated matches, you have to manually ensure `lastIndex` is in the exact right position, as it has no move-ahead capability for matching.

Here's one possible scenario: if you know that the match you care about is always going to be at a position that's a multiple of a number (e.g., `0`, `10`, `20`, etc.), you can just construct a limited pattern matching what you care about, but then manually set `lastIndex` each time before match to those fixed positions. Consider:

```js
var re = /m../y,
  str = "min med max";

console.log(str.match(re)); // [ 'min', index: 0, input: 'min med max', groups: undefined ]
console.log(re.lastIndex); // 3

re.lastIndex = 4;
console.log(str.match(re)); // [ 'med', index: 4, input: 'min med max', groups: undefined ]
console.log(re.lastIndex); // 7

re.lastIndex = 8;
console.log(str.match(re)); // [ 'max', index: 8, input: 'min med max', groups: undefined ]
console.log(re.lastIndex); // 11
```

However, if you're parsing a string that isn't formatted in fixed positions like that, figuring out what to set `lastIndex` to before each match is likely going to be untenable.

There's a saving nuance to consider here. `y` requires that `lastIndex` be in the exact position for a match to occur. But it doesn't strictly require that you manually set `lastIndex`.

Instead, you can construct your expressions in such a way that they capture in each main match everything before and after the thing you care about, up to right before the next thing you'll care to match.

Because `lastIndex` will set to the next character beyond the end of a match, if you've matched everything up to that point, `lastIndex` will always be in the correct position for the `y` pattern to start from the next time.

**Warning**: If you can't predict the structure of the input string in a sufficiently patterned way like that, this technique may not be suitable and you may not be able to use `y`.

Having structured string input is likely the most practical scenario where `y` will be capable of performing repeated matching throughout a string. Consider:

```js
var re = /\d+\.\s(.*?)(?:\s|$)/y
str = "1. min 2. med 3. max";

console.log(str.match(re)); // [ '1. min', 'min', index: 0, input: '1. min 2. med 3. max', groups: undefined ]

console.log(re.lastIndex); // 7 -- correct position!
console.log(str.match(re)); // [ '2. med', 'med', index: 7, input: '1. min 2. med 3. max', groups: undefined ]

console.log(re.lastIndex); // 14 -- correct position!
console.log(str.match(re)); // [ '3. max', 'max', index: 14, input: '1. min 2. med 3. max', groups: undefined ]
```

This works because we knew something ahead of time about the structure of the input string: there is always a numeral prefix like `"1. "` before the desired match (`"min"`, etc.), and either a space after it, or the end of the string (`$` anchor). So the regular expression we constructed captures all of that in each main match, and then we use a matching group `( )` so that the stuff we really care about is separated out for convenience.

After the first match (`"1. min "`), the `lastIndex` is `7`, which is already the position needed to start the next match, for `"2. med "`, and so on.

If you're going to use `y` sticky mode for repeated matches, you'll probably want to look for opportunities to have `lastIndex` automatically positioned as we've just demonstrated.

## Sticky Versus Global

Some readers may be aware that you can emulate something like this `lastIndex`-relative matching with the `g` global match flag and the `exec(..)` method, as so:

```js
var re = /o+./g, // <-- look, `g`!
  str = "foot book more";

console.log(re.exec(str)); // [ 'oot', index: 1, input: 'foot book more', groups: undefined ]
console.log(re.lastIndex); // 4

console.log(re.exec(str)); // [ 'ook', index: 6, input: 'foot book more', groups: undefined ]
console.log(re.lastIndex); // 9

console.log(re.exec(str)); // [ 'or', index: 11, input: 'foot book more', groups: undefined ]
console.log(re.lastIndex); // 13

console.log(re.exec(str)); // null -- no more matches!
console.log(re.lastIndex); // 0 -- starts over now!
```

While it's true that `g` pattern matches with `exec(..)` start their matching from `lastIndex`'s current value, and also update `lastIndex` after each match (or failure), this is not the same thing as `y`'s behavior.

Notice in the previous snippet that `"ook"`, located at position `6`, was matched and found by the second `exec(..)` call, even though at the time, `lastIndex` was `4` (from the end of the previous match). Why? Because as we said earlier, non-sticky matches are free to move ahead in their matching. A sticky mode expression would have failed here, because it would not be allowed to move ahead.

In addition to perhaps undesired move-ahead matching behavior, another downside to just using `g` instead of `y` is that `g` changes the behavior of some matching methods, like `str.match(re)`. Consider:

```js
var re = /o+./g, // <-- look, `g`!
  str = "foot book more";

console.log(str.match(re)); // [ 'oot', 'ook', 'or' ]
```

See how all the matches were returned at once? Sometimes that's OK, but sometimes that's not what you want.

The `y` sticky flag will give you one-at-a-time progressive matching with utilities like `test(..)` and `match(..)`. Just make sure the `lastIndex` is always in the right position for each match!

## Anchored Sticky

As we warned earlier, it's inaccurate to think of sticky mode as implying a pattern starts with `^`. The `^` anchor has a distinct meaning in regular expressions, which is not altered by sticky mode. `^` is an anchor that always refers to the beginning of the input, and is not in any way relative to `lastIndex`.

Besides poor/inaccurate documentation on this topic, the confusion is unfortunately strengthened further because an older pre-**ES6** experiment with sticky mode in Firefox did make `^` relative to `lastIndex`, so that behavior has been around for years. **ES6** elected not to do it that way. `^` in a pattern means **start-of-input** absolutely and only.

As a consequence, a pattern like `/^hamid/y` will always and only find a `"hamid"` match at the beginning of a string, if it's allowed to match there. If `lastIndex` is not `0`, the match will fail. Consider:

```js
var re = /^hamid/y,
  str = "hamid";

console.log(re.test(str)); // true
console.log(re.test(str)); // false
console.log(re.lastIndex); // 0 -- reset after failure

re.lastIndex = 1;
console.log(re.test(str)); // false -- failed for positioning
console.log(re.lastIndex); // 0 -- reset after failure
```

Bottom line: `y` plus `^` plus `lastIndex > 0` is an incompatible combination that will always cause a failed match.

**Note**: While `y` does not alter the meaning of `^` in any way, the `m` multiline mode does, such that `^` means start-of-input or start of text after a newline. So, if you combine `y` and `m` flags together for a pattern, you can find multiple `^`-rooted matches in a string. But **remember**: because it's `y` sticky, you'll have to make sure `lastIndex` is pointing at the correct new line position (likely by matching to the end of the line) each subsequent time, or no subsequent matches will be made.

## Regular Expression `flags`

Prior to **ES6**, if you wanted to examine a regular expression object to see what flags it had applied, you needed to parse them out -- ironically, probably with another regular expression -- from the content of the `source` property, such as:

```js
var re = /foo/ig;

console.log(re.toString()); // "/foo/ig"

var flags = re.toString().match(/\/([gim]*)$/)[1];

console.log(flags); // "gi"
```

As of **ES6**, you can now get these values directly, with the new `flags` property:

```js
var re = /hamed/ig;

console.log(re.toString()); // "/hamed/ig"

var flags = re.toString().match(/\/([gim]*)$/)[1];

console.log(flags); // "gi"
```

As of **ES6**, you can now get these values directly, with the new `flags` property:

```js
var re = /hamid/ig

console.log(re.flags); // "gi"
```

It's a small nuance, but the **ES6** specification calls for the expression's flags to be listed in this order: `"gimuy"`, regardless regardless of what order the original pattern was specified with. That's the reason for the difference between `/ig` and `"gi"`.

No, the order of flags specified or listed doesn't matter.

Another tweak from **ES6** is that the `RegExp(..)` constructor is now `flags`-aware if you pass it an existing regular expression:

```js
var re1 = /hamed*/y;
console.log(re1.source); // "hamed*"
console.log(re1.flags); // "y"

var re2 = new RegExp(re1);
console.log(re2.source); // "hamed*"
console.log(re2.flags); // "y"

var re3 = new RegExp(re1, "ig");
re3.source; // "hamed*"
re3.flags; // "gi"
```

Prior to **ES6**, the `re3` construction would throw an error, but as of **ES6** you can override the flags when duplicating.

## Number Literal Extensions

Prior to **ES5**, number literals looked like the following -- the octal form was not officially specified, only allowed as an extension that browsers had come to de facto agreement on:

```js
let decimal = 23, octal = 027, hexadecimal = 0x17;
```

**Note**: Though you are specifying a number in different bases, the number's mathematic value is what is stored, and the default output interpretation is always base-10. The three variables in the previous snippet all have the `23` value stored in them.

To further illustrate that `027` was a nonstandard form extension, consider:

```js
let decimal = 23, octal = 027, hexadecimal = 0x17;

console.log(Number(decimal), Number(octal), Number(hexadecimal)); // 23 23 23
```

**ES5** continued to permit the browser-extended octal form (including such inconsistencies), except that in strict mode, the octal literal (`027`) form is disallowed. This restriction was done mainly because many developers had the habit (from other languages) of seemingly innocuously prefixing otherwise base-10 numbers with `0`'s for code alignment purposes, and then running into the accidental fact that they'd changed the number value entirely!

**ES6** continues the legacy of changes/variations to how number literals outside base-10 numbers can be represented. There's now an official octal form, an amended hexadecimal form, and a brand-new binary form. For web compatibility reasons, the old octal `027`form will continue to be legal (though unspecified) in non-strict mode, but should really never be used anymore.

Here are the new **ES6** number literal forms (awesome utility):

```js
let decimal = 23,
  octal = 0o27,
  hexadecimal = 0x17,
  binary = 0b10111;

console.log(decimal, octal, hexadecimal, binary); // 23 23 23 23
```

**Note**: You can use uppercase for number literal extensions. like `0O27`, `0X17` and `0B10111`.

The only decimal form allowed is base-10. Octal, hexadecimal, and binary are all integer forms.

And the string representations of these forms are all able to be coerced/converted to their number equivalent:

```js
console.log(Number("23"), Number("0o27"), Number("0x17"), Number("0b10111")); // 23 23 23 23
```

Though not strictly new to **ES6**, it's a little-known fact that you can actually go the opposite direction of conversion (well, sort of):

```js
let number = 23;
console.log(number.toString()); // "23" | or number.toString(10)
console.log(number.toString(8)); // "27" | "0o27"
console.log(number.toString(16)); // "17" | "0x17"
console.log(number.toString(2)); // "10111" | "0b10111"
```

In fact, you can represent a number this way in any base from `2` to `36`, though it'd be rare that you'd go outside the standard bases: 2, 8, 10, and 16.

## Unicode

The Unicode characters that range from `0x0000` to `0xFFFF` contain all the standard printed characters (in various languages) that you're likely to have seen or interacted with. This group of characters is called the Basic Multilingual Plane (BMP). The BMP even contains fun symbols like this cool snowman:  (U+2603).

There are lots of other extended Unicode characters beyond this BMP set, which range up to `0x10FFFF`. These symbols are often referred to as astral symbols, as that's the name given to the set of 16 planes (e.g., layers/groupings) of characters beyond the BMP. Examples of astral symbols include (U+1D11E) and (U+1F4A9).

Prior to **ES6**, JavaScript strings could specify Unicode characters using Unicode escaping, such as:

```js
let snowman = "\u2603";
console.log(snowman); // 
```

However, the `\uXXXX` Unicode escaping only supports four hexadecimal characters, so you can only represent the **B**asic **M**ultilingual **P**lane (BMP) set of characters in this way. To represent an astral character using Unicode escaping prior to **ES6**, you need to use a surrogate pair -- basically two specially calculated Unicode-escaped characters side by side, which JS interprets together as a single astral character:

```js
let note = "\uD834\uDD1E";
console.log(note); // 
```

As of **ES6**, we now have a new form for Unicode escaping (in strings and regular expressions), called Unicode code point escaping:

```js
let note = "\u{1D11E}";
console.log(note); // 
```

As you can see, the difference is the presence of the `{ }` in the escape sequence, which allows it to contain any number of hexadecimal characters. Because you only need six to represent the highest possible code point value in Unicode (i.e., 0x10FFFF), this is sufficient.

## Unicode-Aware String Operations

By default, **JavaScript** string operations and methods are not sensitive to astral symbols in string values. So, they treat each **B**asic **M**ultilingual **P**lane (BMP) character individually, even the two surrogate halves that make up an otherwise single astral character. Consider:

```js
let snowman = "\u2603";
console.log(snowman); // 
console.log(snowman.length); // 1


let note = "\u{1D11E}";
console.log(note); // 
console.log(note.length); // 2
```

**Q**: How do we accurately calculate the length of such a string?

**Answer**: The following trick will work:

```js
let note = "";
console.log(note.length); // 2
console.log([...note].length); // 1
console.log(Array.from(note).length); // 1
```

Recall from the **`for..of` loops** section earlier in this chapter (in this file - near Syntax) that **ES6** strings have built-in iterators. This iterator happens to be Unicode-aware, meaning it will automatically output an astral symbol as a single value. We take advantage of that using the `...` spread operator in an array literal, which creates an array of the string's symbols. Then we just inspect the length of that resultant array. **ES6**'s `Array.from(..)` does basically the same thing as `[...XYZ]`.

**Warning**: It should be noted that constructing and exhausting an iterator just to get the length of a string is quite expensive on performance, relatively speaking, compared to what a theoretically optimized native utility/property would do.

There's a set of code points that modify the previous adjacent character, **k**nown as **C**ombining **D**iacritical Marks (CDM). Consider these two string outputs:

```js
console.log(str1); // ""
console.log(str2); // ""
```

They look the same, but they're not! Here's how we created `str1` and `str2`:

```js
let str1 = "\xE9",
  str2 = "e\u0301";

console.log(str1); // ""
console.log(str2); // ""
```

As you can probably guess, our previous `length` trick doesn't work with `str2`:

```js
let str1 = "\xE9",
  str2 = "e\u0301";

console.log(str1); // ""
console.log(str2); // ""

console.log([...str1].length); // 1
console.log([...str2].length); // 2
```

So what can we do? In this case, we can perform a **Unicode normalization** on the value before inquiring about its length, using the **ES6** `String#normalize(..)` utility:

```js
let str1 = "\xE9",
  str2 = "e\u0301";

console.log(str1.normalize().length); // 1
console.log(str2.normalize().length); // 1

console.log(str1 === str2); // false
console.log(str1 === str2.normalize()); // true
```

Essentially, `normalize(..)` takes a sequence like `"e\u0301"` and normalizes it to `"\xE9"`. Normalization can even combine multiple adjacent combining marks if there's a suitable Unicode character they combine to:

```js
let str1 = "o\u0302\u0300",
  str2 = str1.normalize(),
  str3 = "";

console.log(str1.length); // 3
console.log(str2.length); // 1
console.log(str3.length); // 1

console.log(str2 === str3); // true
```

Unfortunately, normalization isn't fully perfect here, either. If you have multiple combining marks modifying a single character, you may not get the length count you'd expect, because there may not be a single defined normalized character that represents the combination of all the marks. For example:

```js
let str = "e\u0301\u0330";

console.log(str); // "e "
console.log(str.normalize().length); // 2
```

## Character Positioning

Similar to length complications, what does it actually mean to ask, "what is the character at position 2?" The naive pre-**ES6** answer comes from `charAt(..)`, which will not respect the atomicity of an astral character, nor will it take into account combining marks. Consider:

```js
let str1 = "abc\u0301d",
  str2 = "ab\u0107d",
  str3 = "ab\u{1d49e}d";

console.log(str1); // "abcd"
console.log(str2); // "abd"
console.log(str3); // "abd"

console.log(str1.charAt(2)); // "c"
console.log(str2.charAt(2)); // ""
console.log(str3.charAt(2)); // "" <-- unprintable surrogate
console.log(str3.charAt(3)); // "" <-- unprintable surrogate
```

Is **ES6** giving us a Unicode-aware version of `charAt(..)`? Unfortunately, no. At the time of this writing, there's a proposal for such a utility that's under consideration for post-**ES6**.

But with what we explored in the previous section,we can hack an **ES6** answer:

```js
let str1 = "abc\u0301d",
  str2 = "ab\u0107d",
  str3 = "ab\u{1d49e}d";

console.log([...str1.normalize()][2]); // ""
console.log([...str2.normalize()][2]); // ""
console.log([...str3.normalize()][2]); // ""
```

**Warning**: Reminder of an earlier warning: constructing and exhausting an iterator each time you want to get at a single character is... very not ideal, performance wise. Let's hope we get a built-in and optimized utility for this soon, post-**ES6**.

What about a Unicode-aware version of the `charCodeAt(..)` utility? **ES6** gives us `codePointAt(..)`:

```js
let str1 = "abc\u0301d",
  str2 = "ab\u0107d",
  str3 = "ab\u{1d49e}d";

console.log(str1.normalize().codePointAt(2).toString(16)); // "107"
console.log(str2.normalize().codePointAt(2).toString(16)); // "107"
console.log(str3.normalize().codePointAt(2).toString(16)); // "1d49e"
```

What about the other direction? A Unicode-aware version of `String.fromCharCode(..)` is **ES6**'s `String.fromCodePoint(..)`:

```js
console.log(String.fromCodePoint(0x107)); // ""
console.log(String.fromCodePoint(0x1d49e)); // ""
```

So wait, can we just combine `String.fromCodePoint(..)` and `codePointAt(..)` to get a better version of a Unicode-aware `charAt(..)` from earlier? Yeah!

```js
let str1 = "abc\u0301d",
  str2 = "ab\u0107d",
  str3 = "ab\u{1d49e}d";

console.log(String.fromCodePoint(str1.normalize().codePointAt(2))); // ""
console.log(String.fromCodePoint(str2.normalize().codePointAt(2))); // ""
console.log(String.fromCodePoint(str3.normalize().codePointAt(2))); // ""
```

There's quite a few other string methods we haven't addressed here, including `toUpperCase()`, `toLowerCase()`, `substring(..)`, `indexOf(..)`, `slice(..)` and a dozen others. None of these have been changed or augmented for full Unicode awareness, so you should be very careful -- probably just avoid them! -- when working with strings containing astral symbols.

There are also several string methods that use regular expressions for their behavior, like `replace(..)` and `match(..)`. Thankfully, **ES6** brings Unicode awareness to regular expressions, as we covered in **Unicode Flag** earlier in this chapter.

## Unicode Identifier Names

Unicode can also be used in identifier names (variables, properties, etc.). Prior to **ES6**, you could do this with Unicode-escapes, like:

```js
let \u03A9 = 23;
console.log(\u03A9); // 23
```

As of **ES6**, you can also use the earlier explained code point escape syntax:

```js
let \u{2B400} = 23;
console.log(\u{2B400}); // 23
```

## Symbols

With **ES6**, for the first time in quite a while, a new primitive type has been added to **JavaScript**: the `symbol`. Unlike the other primitive types, however, symbols don't have a literal form.

Here's how you create a symbol:

```js
let symbol = Symbol("Hello Guys");
console.log(typeof symbol); // "symbol"
```

Some things to note:

- You cannot and should not use `new` with `Symbol(..)`. It's not a constructor, nor are you producing an object.
- The parameter passed to `Symbol(..)` is optional. If passed, it should be a string that gives a friendly description for the symbol's purpose.
- The `typeof` output is a new value (`"symbol"`) that is the primary way to identify a symbol.

The description, if provided, is solely used for the stringification representation of the symbol:

```js
console.log(symbol.toString()); // "Symbol(Hello Guys)"
```

Similar to how primitive string values are not instances of `String`, symbols are also not instances of `Symbol`. If, for some reason, you want to construct a boxed wrapper object form of a symbol value, you can do the following:

```js
let symbol = Symbol("Hello Guys");
console.log(typeof symbol); // "symbol"
console.log(symbol instanceof Symbol); // false

let symbolObj = Object(symbol);

console.log(symbolObj instanceof Symbol); // true
console.log(symbolObj.valueOf() === symbol); // true
```

**Note**: `symbolObj` in this snippet is interchangeable with `symbol`; either form can be used in all places symbols are utilized. There's not much reason to use the boxed wrapper object form (`symbolObj`) instead of the primitive form (`symbol`). Keeping with similar advice for other primitives, it's probably best to prefer `symbol` to `symbolObj`.

You may use a symbol directly as a property name/key in an object, such as a special property that you want to treat as hidden or meta in usage. It's important to know that although you intend to treat it as such, it is not actually a hidden or untouchable property.

Consider this module that implements the singleton pattern behavior -- that is, it only allows itself to be created once:

```js
const INSTANCE = Symbol("instance");

function HappyFace() {
  if (HappyFace[INSTANCE]) return HappyFace[INSTANCE];

  function smile() { }

  return HappyFace[INSTANCE] = {
    smile: smile
  };
}

let me = HappyFace(),
  you = HappyFace();
console.log(me === you); // true
```

The `INSTANCE` symbol value here is a special, almost hidden, meta-like property stored statically on the `HappyFace()` function object.

## Symbol Registry

You can create symbol values with the global symbol registry. For example:

```js
let symbol = Symbol.for("Hello Guys");
console.log(symbol); // Symbol(Hello Guys)
```

`Symbol.for(..)` looks in the global symbol registry to see if a symbol is already stored with the provided description text, and returns it if so. If not, it creates one to return. In other words, the global symbol registry treats symbol values, by description text, as singletons themselves.

You can retrieve a registered symbol's description text (key) using `Symbol.keyFor(..)`:

```js
let symbol = Symbol.for("Hello Guys");
let info = Symbol.keyFor(symbol);

console.log(symbol); // Symbol(Hello Guys)
console.log(info); // "Hello Guys"

let symbol2 = Symbol.for(info);

console.log(symbol === symbol2); // true
```

## Symbols as Object Properties

If a symbol is used as a property/key of an object, it's stored in a special way so that the property will not show up in a normal enumeration of the object's properties:

```js
let obj = {
  hamed: 23,
  [Symbol("hamid")]: "Hello hamid",
  ali: true
}

console.log(Object.getOwnPropertyNames(obj)); // [ 'hamed', 'ali' ]
```

To retrieve an object's symbol properties:

```js
console.log(Object.getOwnPropertySymbols(obj)); // [ Symbol(hamid) ]
```

This makes it clear that a property symbol is not actually hidden or inaccessible, as you can always see it in the `Object.getOwnPropertySymbols(..)` list.

## Built-In Symbols

**ES6** comes with a number of predefined built-in symbols that expose various meta behaviors on JavaScript object values. However, these symbols are not registered in the global symbol registry, as one might expect.

Instead, they're stored as properties on the `Symbol` function object. For example, in the **`for..of`"** section earlier in this chapter, we introduced the `Symbol.iterator` value;

```js
let array = [1,2,3];
console.log(array[Symbol.iterator]); // [Function: values]
```

The specification uses the `@@` prefix notation to refer to the built-in symbols, the most common ones being: `@@iterator`, `@@toStringTag`,`@@toPrimitive`. Several others are defined as well, though they probably won't be used as often.

---

<!-- Organization -->

**ES6** has several important features that help significantly improve these patterns, including: iterators, generators, modules, and classes.

## Iterators

Iterators are a way of organizing ordered, sequential, pull-based consumption of data.

## `next()` Iteration

Let's look at an array, which is an iterable, and the iterator it can produce to consume its values:

```js
let array = [1, 2, 3];
let it = array[Symbol.iterator]();

console.log(it.next()); // { value: 1, done: false }
console.log(it.next()); // { value: 2, done: false }
console.log(it.next()); // { value: 3, done: false }

console.log(it.next()); // { value: undefined, done: true }
```

Each time the method located at `Symbol.iterator` is invoke on this `array` value, it will produce a new fresh iterator. Most structures will do the same, including all the built-in data structures in **JavaScript**.

The `it` itearator in the previous snippet doesn't report `done: true` when you receive the `3` value. You have to call `next()` again, in essence going beyond the end of the array's values, to get the complete signal `done: true`.

Primitive string values are also iterables by default:

```js
let name = "Hamid Alavi";
let it = name[Symbol.iterator]();

console.log(it.next()); // { value: 'H', done: false }
console.log(it.next()); // { value: 'a', done: false }
console.log(it.next()); // { value: 'm', done: false }
console.log(it.next()); // { value: 'i', done: false }
console.log(it.next()); // { value: 'd', done: false }
console.log(it.next()); // { value: ' ', done: false }
console.log(it.next()); // { value: 'A', done: false }
console.log(it.next()); // { value: 'l', done: false }
console.log(it.next()); // { value: 'a', done: false }
console.log(it.next()); // { value: 'v', done: false }
console.log(it.next()); // { value: 'i', done: false }
console.log(it.next()); // { value: undefined, done: true }

/* or can use:
for (let n of name) {
  console.log(n);
}
*/
```

**Note**: Technically, the primitive value itself isn't iterable, but thanks to **boxing**, `"Hamid Alavi"` is coerced/converted to its `String` object wrapper form, which is an iterable.

**ES6** also includes several new data structures, called collections. These collections are not only iterables themselves, but they also provide API method(s) to generate an iterator, such as:

```js
let map = new Map();

map.set("hamed", 23);
map.set("hamid", 23);
map.set({ isIt: true }, "exist");

let it1 = map[Symbol.iterator]();
let it2 = map.entries();

console.log(it1.next()); // { value: [ 'hamed', 23 ], done: false }
console.log(it1.next()); // { value: [ 'hamid', 23 ], done: false }
console.log(it1.next()); // { value: [ { isIt: true }, 'exist' ], done: false }
console.log(it2.next()); // { value: [ 'hamed', 23 ], done: false }
console.log(it2.next()); // { value: [ 'hamid', 23 ], done: false }
console.log(it2.next()); // { value: [ { isIt: true }, 'exist' ], done: false }
```

The `next(..)` method of an iterator can optionally take one or more arguments. The built-in iterators mostly do not exercise this capability, though a generator's iterator definitely does.

By general convention, including all the built-in iterators, calling `next(..)` on an iterator that's already been exhausted is not an error, but will simply continue to return the result `{ value: undefined, done: true }`.

**Note**: By general convention, an iterator should not produce any more results after having called `return(..)` or `throw(..)`.

## Iterator Loop

As we covered in the **`for..of`** section in earlier, the **ES6** `for..of` loop directly consumes a conforming iterable.

If an iterator is also an iterable, it can be used directly with the `for..of` loop. You make an iterator an iterable by giving it a `Symbol.iterator` method that simply returns the iterator itself:

```js
let it = {
  // make the `it` iterator an iterable
  [Symbol.iterator]() { return this; },
  next() { },
};

console.log(it[Symbol.iterator]() === it); // true
```

Now we can consume the `it` iterator with a `for..of` loop:

```js
for (let v of it) {
  console.log(v);
}
```

To fully understand how such a loop works, call some hard examples:

```js
for (var v, res; (res = it.next()) && !res.done;) {
  v = res.value;
  console.log(v);
}
```

If you look closely, you'll see that `it.next()` is called before each iteration, and then `res.done` is consulted. If `res.done` is `true`, the expression evaluates to `false` and the iteration doesn't occur.

In addition to the standard built-in iterators, you can make your own! All it takes to make them interoperate with **ES6**'s consumption facilities (e.g., the `for..of`loop and the `...` operator) is to adhere to the proper interface(s).

Let's try constructing an iterator that produces the infinite series of numbers in the Fibonacci sequence:

```js
let Fib = {
  [Symbol.iterator]() {
    let n1 = 1, n2 = 1;

    return {
      // make the iterator an iterable
      [Symbol.iterator]() { return this; },

      next() {
        let current = n2;
        n2 = n1;
        n1 = n1 + current;
        return { value: current, done: false };
      },

      return(v) {
        console.log(
          "Fibonacci sequence abandoned."
        );
        return { value: v, done: true };
      }
    };
  }
};

for (let v of Fib) {
  console.log(v); // 1 1 2 3 5 8 13 21 34 55

  if (v > 50) break;
}
let Fib = {
  [Symbol.iterator]() {
    let n1 = 1, n2 = 1;

    return {
      // make the iterator an iterable
      [Symbol.iterator]() { return this; },

      next() {
        let current = n2;
        n2 = n1;
        n1 = n1 + current;
        return { value: current, done: false };
      },

      return(v) {
        console.log(
          "Fibonacci sequence abandoned."
        );
        return { value: v, done: true };
      }
    };
  }
};

for (let v of Fib) {
  console.log(v); // 1 1 2 3 5 8 13 21 34 55

  if (v > 50) break;
}
// Fibonacci sequence abandoned.
```

**Warning**: If we hadn't inserted the `break` condition, this `for..of` loop would have run forever, which is probably not the desired result in terms of breaking your program!

The `Fib[Symbol.iterator]()` method when called returns the iterator object with `next()` and `return(..)` methods on it. State is maintained via `n1` and `n2` variables, which are kept by the closure.

## Iterator Consumption

We've already shown consuming an iterator item by item with the `for..of` loop. But there are other **ES6** structures that can consume iterators.

Let's consider the iterator attached to this array (though any iterator we choose would have the following behaviors):

```js
let n = [1, 2, 3, 4, 5, 6, 7, 8, 9];
```

The `...` spread operator fully exhausts an iterator. Consider:

```js
let a = [1, 2, 3, 4, 5];
function hamid(a, b, c, d, e) {
  console.log(a + b + c + d + e);
}

hamid(...a); // 15 - a array
```

`...` can also spread an iterator inside an array:

```js
let a = [1, 2, 3, 4, 5];
let b = [0, ...a, 6];
console.log(b); // [ 0, 1, 2, 3, 4, 5, 6 ]
```

Array destructuring can partially or completely ((if paired with a `...` rest/gather operator) consume an iterator:

```js
let a = [1, 2, 3, 4, 5];
let it = a[Symbol.iterator]();

let [x, y] = it;
let [z, ...w] = it;

console.log(it.next()); // { value: undefined, done: true }
console.log(x); // 1
console.log(y); // 2
console.log(z); // 3
console.log(w); // [ 4, 5 ]
```

## Generators

All functions run to completion, right? In other words, once a function starts running, it finishes before anything else can interrupt.

As of **ES6**, a new somewhat exotic form of function is being introduced, called a **generator**. A generator can pause itself in mid-execution, and can be resumed either right away or at a later time. So it clearly does not hold the run-to-completion guarantee that normal functions do.

## Syntax

The generator function is declared with this new syntax:

```js
function* hamid() {
  // do something
}
```

The position of the `*` is not functionally relevant. The same declaration could be written as any of the following:

```js
function *hamid() { /* do something */ }
function* hamid() { /* do something */ }
function * hamid() { /* do something */ }
function*hamid() { /* do something */ }
```

You are free to choose aal above stylistic code.

Also there's a concise generator form in object literals:

```js
let hamed = {
  *hamid() { /* do something */ }
}
```

## Executing a Generator

Though a generator is declared with `*`, you still execute it like a normal function:

```js
hamid();
```

You can still pass it arguments, as in:

```js
function* hamed(x, y) {
  // do something
}

hamed(15, 8);
```

The major difference is that executing a generator, like `hamed(15, 8)` doesn't actually run the code in the generator. Instead, it produces an iterator that will control the generator to execute its code.

We'll come back to this later in**Iterator Control** but briefly:

```js
function* hamid() {
  // do something
}

let it = hamid();
```

## `yield`

Generators also have a new keyword you can use inside them, to signal the pause point: `yield`. Consider:

```js
function* hamed() {
  let x = 10, y = 20;
  yield;
  let z = x + y;
}
```

In this `*hamed()` generator, the operations on the first two lines would run at the beginning, then `yield` would pause the generator. If and when resumed, the last line of `*hamid()` would run. `yield` can appear any number of times (or not at all, technically!) in a generator.

You can even put `yield` inside a loop, and it can represent a repeated pause point. In fact, a loop that never completes just means a generator that never completes, which is completely valid, and sometimes entirely what you need.

`yield` is not just a pause point. It's an expression that sends out a value when pausing the generator. Here's a `while..true` loop in a generator that for each iteration `yield`s a new random number:

```js
function* hamid() {
  while (true) {
    yield Math.random();
  }
}
```

The `yield ..` expression not only sends a value -- `yield` without a value is the same as `yield undefined` -- but also receives (e.g., is replaced by) the eventual resumption value. Consider:

```js
function* hamed() {
  let x = yield 10;
  console.log(x);
}

let it = hamed();

console.log(it.next()); // { value: 10, done: false }
```

This generator will first `yield` out the value `10` when pausing itself. When you resume the generator -- using the `it.next(..)` we referred to earlier -- whatever value (if any) you resume with will replace/complete the whole `yield 10` expression, meaning that value will be assigned to the `x` variable.

A `yield ..` expression can appear anywhere a normal expression can. For example:

```js
function* ali() {
  let array = [yield 1, yield 2, yield 3];
  console.log(array, yield 4);
}

let it = ali();

console.log(it.next()); // { value: 1, done: false }
console.log(it.next()); // { value: 2, done: false }
console.log(it.next()); // { value: 3, done: false }
console.log(it.next()); // { value: 4, done: false }
```

`*ali()` here has four `yield ..` expressions. Each `yield` results in the generator pausing to wait for a resumption value that's then used in the various expression contexts.

`yield` is not technically an operator, though when used like `yield 1` it sure looks like it. Because `yield` can be used all by itself as in `let x = yield;`, thinking of it as an operator can sometimes be confusing.

Technically, `yield ..` is of the same "expression precedence" -- similar conceptually to operator precedence -- as an assignment expression like `a = 3`. That means `yield ..` can basically appear anywhere `a = 3` can validly appear. Let's illustrate the symmetry:

```js
let a, b;

a = 3; // valid
b = 2 + a = 3; // invalid
b = 2 + (a = 3); // valid

yield 3; // valid
a = 2 + yield 3; // invalid
a = 2 + (yield 3); // valid
```

If you need `yield ..` to appear in a position where an assignment like `a = 3` would not itself be allowed, it needs to be wrapped in the `()`.

Because of the low precedence of the `yield` keyword, almost any expression after a `yield ..` will be computed first before being sent with `yield`. Only the `...` spread operator and the `,` comma operator have lower precedence, meaning they'd bind after the `yield` has been evaluated.

So just like with multiple operators in normal statements, another case where `()` might be needed is to override (elevate) the low precedence of `yield`, such as the difference between these expressions:

```js
yield 2 + 3; // same as `yield (2 + 3)`

(yield 2) + 3; // `yield 2` first, then `+ 3`
```

Just like `=` assignment, `yield` is also **right-associative**, which means that multiple `yield` expressions in succession are treated as having been `(..)` grouped from right to left. So, `yield yield yield 3` is treated as `yield (yield (yield 3))`. A **left-associative** interpretation like `((yield) yield) yield 3` would make no sense.

Just like with operators, it's a good idea to use `(..)` grouping, even if not strictly required, to disambiguate your intent if `yield` is combined with other operators or `yield`s.

## `yield *`

In the same way that the `*` makes a `function` declaration into `function*` generator declaration, a `*` makes `yield` into `yield *`, which is a very different mechanism, called **yield delegation**. Grammatically, `yield *..` will behave the same as a `yield ..`.

`yield *..` requires an iterable; it then invokes that iterable's iterator, and delegates its own host generator's control to that iterator until it's exhausted. Consider:

```js
function* reza() {
  yield* [1, 2, 3];
}
```

Note: As with the `*` position in a generator's declaration (discussed earlier), the `*` positioning in `yield *` expressions is stylistically up to you (`yield* ..` or `yield *..`).

The `[1,2,3]` value produces an iterator that will step through its values, so the `*reza()` generator will yield those values out as it's consumed. Another way to illustrate the behavior is in yield delegating to another generator:

```js
function* hamed() {
  yield 1;
  yield 2;
  yield 3;
}

function* hamid() {
  yield* hamed();
}
```

The iterator produced when `*hamid()` calls `*hamed()` is delegated to via `yield *`, meaning whatever value(s) `*hamed()` produces will be produced by `*hamid()`.

Whereas with `yield ..` the completion value of the expression comes from resuming the generator with `it.next(..)`, the completion value of the `yield *..` expression comes from the return value (if any) from the delegated-to iterator.

Built-in iterators generally don't have return values. But if you define your own custum iterator (or generator), you can design it to `return` a value, which `yield *..` would capture:

```js
function* hamed() {
  yield 1;
  yield 2;
  yield 3;
  return 4;
}

function* hamid() {
  let x = yield* hamed();
  console.log("x:", x);
}

for (let v of hamid()) {
  console.log(v); // 1 2 3 "x: " 4
```

While `1`, `2`, and `3` values are `yield`ed out of `*hamed()` and then out of `*hamid()`, the `4` value returned from `*hamed()` is the completion value of the `yield *hamed()` expression, which then gets assigned to `x`.

Because `yield *` can call another generator (by way of delegating to its iterator), it can also perform a sort of generator recursion by calling itself:

```js
function* hamed(x) {
  if (x < 3) {
    x = yield* hamed(x + 1);
  }
  return x * 2;
}

// let it = hamed(1);
// console.log(it.next()); // { value: 24, done: true }
```

The result from `hamed(1)` and then calling the iterator's `next()` to run it through its recursive steps will be `24`. The first `*hamed(..)` run has `x` at value `1`, which is `x < 3`. `x + 1` is passed recursively to `*hamed(..)`, so `x` is then `2`. One more recursive call results in `x` of `3`.

Now, because `x < 3` fails, the recursion stops, and `return 3 * 2` gives `6` back to the previous call's `yield *..` expression, which is then assigned to `x`. Another `return 6 * 2` returns `12` back to the previous call's `x`. Finally `12 * 2`, or `24`, is returned from the completed run of the `*hamed(..)` generator.

## Iterator Control

Earlier, we briefly introduced the concept that generators are controlled by iterators. Let's fully dig into that now.

Recall the recursive `*hamed(..)`. Here's how we'd run it:

```js
function* hamed(x) {
  if (x < 3) {
    x = yield* hamed(x + 1);
  }
  return x * 2;
}

let it = hamed(1);
console.log(it.next()); // { value: 24, done: true }
```

In this case, the generator doesn't really ever pause, as there's no `yield ..` expression. Instead, `yield *` just keeps the current iteration step going via the recursive call. So, just one call to the iterator's `next()` function fully runs the generator.

Now let's consider a generator that will have multiple steps and thus multiple produced values:

```js
function* hamid() {
  yield 1;
  yield 2;
  yield 3;
}
```

We already know we can consume an iterator, even one attached to a generator like `*hamid()` with a `for..of` loop:

```js
for (let v of hamid()) {
  console.log(v); // 1 2 3
}
```

**Note**: The `for..of` loop requires an iterable. A generator function reference (like `hamid`) by itself is not an iterable; you must execute it with `hamid()` to get the iterator (which is also an iterable). You could theoretically extend the `GeneratorPrototype` (the prototype of all generator functions) with a `Symbol.iterator` function that essentially just does `return this()`. That would make the `hamid` reference itself an iterable, which means `for (let v of hamid) { .. }` (notice no `()` on `hamid`) will work.

Let's instead iterate the generator manually:

```js
function* hamid() {
  yield 1;
  yield 2;
  yield 3;
}

let it = hamid();

console.log(it.next()); // { value: 1, done: false }
console.log(it.next()); // { value: 2, done: false }
console.log(it.next()); // { value: 3, done: false }
console.log(it.next()); // { value: undefined, done: true }
```

If you look closely, there are three `yield` statements and four `next()` calls.  That may seem like a strange mismatch. In fact, there will always be one more `next()` call than `yield` expression, assuming all are evaluated and the generator is fully run to completion.

Recall that the `yield ..` expression will be completed by the value you resume the generator with. That means the argument you pass to `next(..)` completes whatever `yield ..` expression is currently paused waiting for a completion. Let's illustrate this perspective this way:

```js
function* hamed() {
  let x = yield 1;
  let y = yield 2;
  let z = yield 3;

  console.log(x, y, z);
}
```

In this snippet, each `yield ..` is sending a value out (`1`, `2`, `3`), but more directly, it's pausing the generator to wait for a value. In other words, it's almost like asking the question, **What value should I use here? I'll wait to hear back**.

Now, here's how we control `*hamed()` to start it up:

```js
let it = hamed();

console.log(it.next()); // { value: 1, done: false }
```

That first `next()` call is starting up the generator from its initial paused state, and running it to the first `yield`. At the moment you call that first `next()`, there's no `yield ..` expression waiting for a completion. If you passed a value to that first `next()` call, it would currently just be thrown away, because no `yield` is waiting to receive such a value.

Now, let's answer the currently pending question, **What value should I assign to `x`**? We'll answer it by sending a value to the next `next(..)` call:

```js
console.log(it.next("hamed")); // { value: 2, done: false }
```

Now, the `x` will have the value `"hamed"`, but we've also asked a new question, **What value should I assign to `y`**? And we answer:

```js
console.log(it.next("hamid")); // { value: 3, done: false }
```

Answer given, another question asked. Final answer:

```js
console.log(it.next("ali")); // "hamed" "hamid" "ali"
// { value: undefined, done: true }
```

Now it should be clearer how each `yield ..` **question** is answered by the next `next(..)` call, and so the **extra** `next()` call we observed is always just the initial one that starts everything going.

Let's put all those steps together:

```js
function* hamed() {
  let x = yield 1;
  let y = yield 2;
  let z = yield 3;

  console.log(x, y, z);
}

let it = hamed();

// start up the generator
console.log(it.next()); // { value: 1, done: false }

// answer first question
console.log(it.next("hamed")); // { value: 2, done: false }

// answer second question
console.log(it.next("hamid")); // { value: 3, done: false }

// answer third question
console.log(it.next("ali")); // "hamed" "hamid" "ali" | { value: undefined, done: true }
```

## Completion

the iterator attached to a generator supports the optional `return(..)` and `throw(..)` methods. Both of them have the effect of aborting a paused generator immediately. Consider:

```js
function* hamid() {
  yield 1;
  yield 2;
  yield 3;
}

let it = hamid();

console.log(it.next()); // { value: 1, done: false }
console.log(it.return(23)); // { value: 23, done: true }
console.log(it.next()); // { value: undefined, done: true }
```

`return(23)` is kind of like forcing a `return 23` to be processed at exactly that moment, such that you get the specified value right back. Once a generator is completed, either normally or early as shown, it no longer processes any code or returns any values.

In addition to `return(..)` being callable manually, it's also called automatically at the end of iteration by any of the **ES6** constructs that consume iterators, such as the `for..of` loop and the  `...` spread operator.

The purpose for this capability is so the generator can be notified if the controlling code is no longer going to iterate over it anymore, so that it can perhaps do any cleanup tasks (freeing up resources, resetting staus, etc.). Identical to a normal function cleanup pattern, the main way to accomplish this is to use a `finally` clause:

```js
function* hamid() {
  try {
    yield 1;
    yield 2;
    yield 3;
  }
  finally {
    console.log("cleanup!");
  }
}

// this way
for (let v of hamid()) {
  console.log(v); // 1 2 3 "cleanup!"
}

// or this way
let it = hamid();
console.log(it.next()); // { value: 1, done: false } "cleanup!"
console.log(it.return(23)); // { value: 23, done: true }
```

**Warning**: Do not put a `yield` statement inside the `finally` clause! It's valid and legal, but it's a really terrible idea. It acts in a sense as deferring the completion of the `return(..)` call you made, as any `yield ..` expressions in the `finally` clause are respected to pause and send messages; you don't immediately get a completed generator as expected. There's basically no good reason to opt in to that crazy bad part, so avoid doing so!

In addition to the previous snippet showing how `return(..)` aborts the generator while still triggering the `finally` clause, it also demonstrates that a generator produces a whole new iterator each time it's called. In fact, you can use multiple iterators attached to the same generator concurrently:

```js
function* hamed() {
  yield 1;
  yield 2;
  yield 3;
}

let it1 = hamed();
console.log(it1.next()); // { value: 1, done: false }
console.log(it1.next()); // { value: 2, done: false }

let it2 = hamed();
console.log(it2.next()); // { value: 1, done: false }

console.log(it1.next()); // { value: 3, done: false }

console.log(it2.next()); // { value: 2, done: false }
console.log(it2.next()); // { value: 3, done: false }

console.log(it2.next()); // { value: undefined, done: true }
console.log(it1.next()); // { value: undefined, done: true }
```

Instead of calling `return(..)`, you can call `throw(..)`. Just like `return(x)` (like `return(23)`) is essentially injecting a `return x` into the generator at its current pause point, calling `throw(x)` is essentially like injecting a `throw x` at the pause point.

Other than the exception behavior, `throw(..)` produces the same sort of early completion that aborts the generator's run at its current pause point. For example:

```js
function* hamid() {
  yield 1;
  yield 2;
  yield 3;
}

let it = hamid();

console.log(it.next()); // { value: 1, done: false }

try {
  it.throw("Oops!");
}
catch (err) {
  console.log(err); // Exception: "Oops!"
}

console.log(it.next()); // { value: undefined, done: true }
```

Because `throw(..)` basically injects a `throw ..` in replacement of the `yield 1` line of the generator, and nothing handles this exception, it immediately propagates back out to the calling code, which handles it with a `try..catch`.

Unlike `return(..)`, the iterator's `throw(..)` method is never called automatically.

Of course, though not shown in the previous snippet, if a `try..finally` clause  was waiting inside the generator when you call `throw(..)`, the `finally` clause would be given a chance to complete before the exception is propagated back to the calling code.

## Transpiling a Generator

Is it possible to represent a generator's capabilities prior to **ES6**? It turns out it is, and there are several great tools that do.

But just to better understand generators, let's try our hand at manually converting. Basically,we're going to create a simple closure-based state machine.

We'll keep our source generator really simple:

```js
function* hamed() {
  let x = yield 23;
  console.log(x);
}
```

To start, we'll need a function called `hamed()` that we can execute, which needs to return an iterator:

```js
function hamed() {
  return {
    next(v) {
      console.log(v);
    }
    // we'll skip `return(..)` and `throw(..)`
  }
}
```

Now, we need some inner variable to keep track of where we are in the steps of our **generator**s logic. We'll call it `state`. There will be three states: `0` initially, `1` while waiting to fulfill the `yield` expression, and `2` once the generator is complete.

## Generator Uses

So, now that we much more deeply understand how generators work, what are they useful for?

We've seen **two** major patterns:

- **Producing a series of values**: This usage can be simple (e.g., random strings or incremented numbers), or it can represent more structured data access (e.g., iterating over rows returned from a database query).

  Either way, we use the iterator to control a generator so that some logic can be invoked for each call to `next(..)`. Normal iterators on data structures merely pull values without any controlling logic.
- **Queue of tasks to perform serially**: This usage often represents flow control for the steps in an algorithm, where each step requires retrieval of data from some external source. The fulfillment of each piece of data may be immediate, or may be asynchronously delayed.

  From the perspective of the code inside the generator, the details of sync or async at a `yield` point are entirely opaque. Moreover, these details are intentionally abstracted away, such as not to obscure the natural sequential expression of steps with such implementation complications. Abstraction also means the implementations can be swapped/refactored often without touching the code in the generator at all.

When generators are viewed in light of these uses, they become a lot more than just a different or nicer syntax for a manual state machine. They are a powerful abstraction tool for organizing and controlling orderly production and consumption of data.

## Modules

### The Old Way

The traditional module pattern is based on an outer function with inner variables and functions, and a returned **public API** with methods that have closure over the inner data and capabilities. It's often expressed like this:

```js
function hello(name) {
  function greet() {
    console.log(`Hello ${name}!`);
  }

  // public API
  return {
    greet
  }
}

let me = hello("Hamid");
me.greet(); // "Hello Hamid!"
```

The `hello(..)` module can produce multiple instances by being called subsequent times. Sometimes, a module is only called for as a singleton (i.e., it just needs one instance), in which case a slight variation on the previous snippet, using an IIFE, is common:

```js
let me = (function hello(name) {
  function greet() {
    console.log(`Hello ${name}!`);
  }

  // public API
  return {
    greet
  }
})("Hamid");

me.greet(); // "Hello Hamid!"
```

This pattern is tried and tested. It's also flexible enough to have a wide assortment of variations for a number of different scenarios.

## Moving Forward

As of **ES6**, we no longer need to rely on the enclosing function and closure to provide us with module support. **ES6** modules have first class syntactic and functional support.

Before we get into the specific syntax, it's important to understand some fairly significant conceptual differences with **ES6** modules compared to how you may have dealt with modules in the past:

- **ES6** uses file-based modules, meaning one module per file. At this time, there is no standardized way of combining multiple modules into a single file.

  That means that if you are going to load **ES6** modules directly into a browser web application, you will be loading them individually, not as a large bundle in a single file as has been common in performance optimization efforts.

  It's expected that the contemporaneous advent of HTTP/2 will significantly mitigate any such performance concerns, as it operates on a persistent socket connection and thus can very efficiently load many smaller files in parallel and interleaved with one another.
- The API of an **ES6** module is static. That is, you define statically what all the top-level exports are on your module's public API, and those cannot be amended later.

  Some uses are accustomed to being able to provide dynamic API definitions, where methods can be added/removed/replaced in response to runtime conditions. Either these uses will have to change to fit with **ES6** static APIs, or they will have to restrain the dynamic changes to properties/methods of a second-level object.
- **ES6** modules are singletons. That is, there's only one instance of the module, which maintains its state. Every time you import that module into another module, you get a reference to the one centralized instance. If you want to be able to produce multiple module instances, your module will need to provide some sort of factory to do it.
- The properties and methods you expose on a module's public API are not just normal assignments of values or references. They are actual bindings (almost like pointers) to the identifiers in your inner module definition.

  In pre-**ES6** modules, if you put a property on your public API that holds a primitive value like a number or string, that property assignment was by value-copy, and any internal update of a corresponding variable would be separate and not affect the public copy onthe API object.

  With **ES6**, exporting a local private variable, even if it currently holds a primitive string/number/etc, exports a binding to the variable. If the module changes the variable's value, the external import binding now resolves to that new value.
- Importing a module is the same thing as statically requesting it to load (if it hasn't already). If you're in a browser, that implies a blocking load over the network. If you're on a server (i.e., Node.js), it's a blocking load from the filesystem.

  However, don't panic about the performance implications. Because **ES6** modules have static definitions, the import requirements can be statically scanned, and loads will happen preemptively, even before you've used the module.

  **ES6** doesn't actually specify or handle the mechanics of how these load requests work. There's a separate notion of a Module Loader, where each hosting environment (browser, Node.js, etc.) provides a default Loader appropriate to the environment. The importing of a module uses a string value to represent where to get the module (URL, file path, etc.), but this value is opaque in your program and only meaningful to the Loader itself.

  You can define your own custom Loader if you want more fine-grained control than the default Loader affords -- which is basically none, as it's totally hidden from your program's code.

### The New Way

The two main new keywords that enable **ES6** modules are `import` and `export`. There's lots of nuance to the syntax, so let's take a deeper look.

**Warning**: An important detail that's easy to overlook: both `import` and `export` must always appear in the top-level scope of their respective usage. For example, you cannot put either an `import` or `export` inside an `if` conditional; they must appear outside of all blocks and functions.

### `export`

The `export` keyword is either put in front of a declaration, or used as an operator (of sorts) with a special list of bindings to export. Consider:

```js
export function hamed() {
  // do something
}

export let age = 23;

let hamid = [1, 2, 3];
export { hamid };
```

Another way of expressing the same exports:

```js
function hamed() {
  // do something
}

let age = 23;
let hamid = [1, 2, 3];

export { hamed, age, hamid };
```

These are all called named exports, as you are in effect exporting the name bindings of the variables/functions/etc.

Anything you don't label with `export` stay private inside the scope of the module. That is, although something like `let hamid = ..` looks like it's declaring at the top-level global scope, the top-level scope is actually the module itself; there is no global scope in modules.

**Note**: Modules do still have access to `window` and all the "globals" that hang off it, just not as lexical top-level scope. However, you really should stay away from the globals in your modules if at all possible.

You can also **rename** (aka alias) a module member during named export:

```js
function hamed() { }
export { hamed as ali };
```

When this module is imported, only the `ali` member name is available to import; `hamed` stays hidden inside the module.

Module exports are not just normal assignments of values or references, as you're accustomed to with the `=` assignment operator. Actually, when you export something, you're exporting a binding (kinda like a **pointer**) to that thing (variable, etc.).

Within your module, if you change the value of a variable you already exported a binding to, even if it's already been imported, the imported binding will resolve to the current (updated) value. Consider:

```js
let age = 23;
export { age };

// later
age = 24;
```

When this module is imported, regardless of whether that's before or after the `age = 24` setting, once that assignment has happened, the imported binding resolves to the `24` value, not `23`.

**Read**: That's because the binding is, in essence, **a reference to, or a pointer to**, the `age` variable itself, **rather than a copy of its value**. This is a mostly unprecedented concept for **JavaScript** introduced with **ES6** module bindings.

A default export sets a particular exported binding to be the default when importing the module. The name of the binding is literally `default`. When importing module bindings you can also rename them, as you commonly will with a default export. There can only be one `default` per module definition.

There's a subtle nuance to default export syntax that you should pay close attention to. Compare these two snippets:

```js
function hamid() { }

export default hamid;
```

And this one:

```js
function hamid() { }

export { hamid as default };
```

In the first snippet, you are exporting a binding to the function expression value at that moment, not to the identifier `hamid`. in other words, `export default ..` takes an expression. If you later assign `hamid` to a different value inside your module, the module import still reveals the function originally exported, not the new value.

By the way, the first snippet could also have been written as:

```js
export default function hamid() { }
```

**Warning**: Although the `function hamid..` part here is technically a function expression, for the purposes of the internal scope of the module, it's treated like a function declaration, in that the `hamid` name is bound in the module's top-level scope (**hoisting**). The same is true for `export default class Hamid..` . However, while you can do `export let hamid = ..`, you currently cannot do `export default let hamid = ..` (or `let` or `const`), in a frustrating case of inconsistency.

Recall the second snippet again:

```js
function hamid() { }

export { hamid as default };
```

In this version of the module export, the default export binding is actually to the `hamid` identifier rather than its value, so you get the previously described binding behavior (i.e., if you later change `hamid`'s value, the value seen on the import side will also be updated).

Be very careful of this subtle gotcha in default export syntax, especially if your logic calls for export values to be updated. If you never plan to update a default export's value, `export default ..` is fine. If you do plan to update the value, you must use `export { .. as default }` . Either way, make sure to comment your code to explain your intent!

Because there can only be one `default` per module, you may be tempted to design your module with one default export of an object with all your API methods on it, such as:

```js
export default {
hamed() { .. },
hamid() { .. },
ali() { .. },
reza() { .. },
majid() { .. },
mehrdad() { .. },
morteza() { .. },
..
};
```

We would probably recommend you not mix default export with named exports, especially if you have a large API and refactoring to separate modules isn't practical or desired. In that case, just use all named exports, and document that consumers of your module should probably use the `import * as ..` approach to bring the whole API in at once on a single namespace.

Other than the `export default ..` form that exports an expression value binding, all other export forms are exporting bindings to local identifiers. For those bindings, if you change the value of a variable inside a module after exporting, the external imported binding will access the updated value:

```js
var hamed = 23;
export { hamed as default };

export var hamid = "hello world";

hamed = 10;
hamid = "cool";
```

When you import this module, the `default` and `hamid` exports will be bound to the local variables `hamed` and `hamid`, meaning they will reveal the updated `10` and `"cool"` values. The values at time of export are irrelevant. The values at time of import are irrelevant. The bindings are live links, so all that matters is what the current value is when you access the binding.

**Warning**: Two-way bindings are not allowed. If you import a `hamed` from a module, and try to change the value of your imported `hamed` variable, an error will be thrown!

You can also re-export another module's exports, such as:

```js
export { hamed, hamid } from "ali";
export { hamed as HAMED, hamid as HAMID } from "ali";
export * from "ali";
```

Those forms are similar to just first importing from the `"ali"` module then listing its members explicitly for export from your module. However, in these forms, the members of the `"ali"` module are never imported to your module's local scope; they sort of pass through untouched.

### `import`

To import a module, unsurprisingly you use the `import` statement. Just as `export` has several nuanced variations, so does `import`, so spend plenty of time considering the following issues and experimenting with your options.

If you want to import certain specific named members of a module's API into your top-level scope, you use this syntax:

```js
import { hamed, hamid, ali } from "reza";
```

**Warning**: The `{ .. }` syntax here may look like an object literal, or even an object destructuring syntax. However, its form is special just for modules, so be careful not to confuse it with other `{ .. }` patterns elsewhere.

The `"reza"` string is called a module specifier. Because the whole goal is statically analyzable syntax, the module specifier must be a string literal; it cannot be a variable holding the string value.

From the perspective of your **ES6** code and the **JavaScript** engine itself, the contents of this string literal are completely opaque and meaningless. The module loader will interpret this string as an instruction of where to find the desired module, either as a URL path or a local filesystem path.

The `hamed`, `hamid`, and `ali` (`foo`, `bar`, and `baz` in world) identifiers listed must match named exports on the module's API. They are bound as top-level identifiers in your current scope:

```js
import { hamed } from "hamed";

hamed();
```

You can rename the bound identifiers imported, as:

```js
import { hamed as hamedFunc } from "hamed";

hamedFunc();
```

If the module has just a default export that you want to import and bind to an identifier, you can opt to skip the `{ .. }` surrounding syntax for that binding. The `import` in this preferred case gets the nicest and most concise of the `import` syntax forms:

```js
import hamed from "hamed";
// or
import { default as hamed } from "hamed";
```

You can also import a default export along with other named exports, if the module has such a definition. Recall this module definition from earlier:

```js
export default function hamed() { .. }
export function hamid() { .. }
export function ali() { .. }
```

To import that module's default export and its two named exports:

```js
import HAMEDFN, { hamid, ali as ALI } from "reza";

HAMEDFN();
hamid();
ALI();
```

The preference might be to import everything from the module into a single namespace, rather than importing individual members, each directly into the scope. Fortunately, the `import` statement has a syntax variation that can support this style of module consumption, called namespace import.

Consider a `"reza"` module exported as:

```js
export function hamid() { .. }
export let x = 23;
export function ali() { .. }
```

You can import that entire API to a single module namespace binding:

```js
import * as reza from "reza";

reza.hamid();
console.log(reza.x); // 23
reza.ali();
```

**Note**: The `* as ..` clause requires the `*` wildcard. In other words, you cannot do something like `import { hamid, x } as reza from "reza"` to bring in only part of the API but still bind to the `reza` namespace.

If the module you're importing with `* as ..` has a default export, it is named `default` in the namespace specified. You can additionally name the default import outside of the namespace binding, as a top-level identifier. Consider a `"world"` module exported as:

```js
export default function hamed() { .. }
export function hamid() { .. }
export function ali() { .. }
```

And this `import`:

```js
import hamedfn, * as hello from "world";

// edited in behind
hamedfn();
hello.default();
hello.hamid();
hello.ali();
```

While this syntax is valid, it can be rather confusing that one method of the module (the default export) is bound at the top-level of your scope, whereas the rest of the named exports (and one called `default`) are bound as properties on a differently named (`hello`) identifier namespace.

As we mentioned earlier, our suggestion would be to avoid designing your module exports in this way, to reduce the chances that your module's users will suffer these strange quirks.

All imported bindings are immutable and/or read-only. Consider the previous import; all of these subsequent assignment attempts will throw `TypeError`s:

```js
import hamedfn, * as hello from "world";

hamedfn = 23; // (runtime) TypeError!
hello.default = 23; // (runtime) TypeError!
hello.hamid = 23; // (runtime) TypeError!
hello.ali = 23; // (runtime) TypeError!
```

Immutable/read-only nature of your local imported bindings enforces that you cannot change them from the imported bindings, hence the `TypeError`s. That's pretty important, because without those protections, your changes would end up affecting all other consumers of the module (**remember: singleton**), which could create some very surprising side effects!

Declarations that occur as a result of an `import` are **hoisted**. Consider

```js
hamed();

import { hamed } from "hamed";
```

The most basic form of the `import` looks like this:

```js
import "hamed";
```

This form does not actually import any of the module's bindings into your scope. It loads (if not already loaded), compiles (if not already compiled), and evaluates (if not already run) the `"hamed"` module.

## Classes

From nearly the beginning of JavaScript, syntax and development patterns have all **strived** (read: **struggled**) to put on a facade of supporting **class-oriented** development. With things like `new` and `instanceof` and a `.constructor` property, who couldn't help but be teased that **JavaScript** had classes hidden somewhere inside its prototype system?

Although **JavaScript**'s prototype mechanism doesn't work like traditional classes, that doesn't stop the strong tide of demand on the language to extend the syntactic sugar so that expressing **classes** looks more like real classes. Enter the **ES6** `class` keyword and its associated mechanism.

At the heart of the new **ES6** class mechanism is the class keyword, which identifies a block where the contents define the members of a function's prototype. Consider:

```js
class Hamed {
  constructor(a, b) {
    this.x = a;
    this.y = b;
  }

  fetchXY() {
    return this.x * this.y;
  }
}
```

Some things to note:

- `class Hamed` implies creating a (special) function of the name `Hamed`, much like you did pre-**ES6**.
- `constructor(..)` identifies the signature of that `Hamed(..)` function, as well as its body contents.
- Class methods use the same **concise method** syntax available to object literals. This also includes the **concise generator** (search and see before topics for more information), as well as the **ES5** getter/setter syntax. However, class methods are non-enumerable whereas object methods are by default enumerable.
- Unlike object literals, there are no commas separating members in a `class` body! In fact, they're not even allowed.

The `class` syntax definition in the previous snippet can be roughly thought of as this pre-**ES6** equivalent, which probably will look fairly familiar to those who've done prototype-style coding before:

```js
function Hamed(a, b) {
  this.x = a;
  this.y = b;
}

Hamed.prototype.fetchXY = function () {
  return this.x * this.y;
}
```

In either the pre-**ES6** form or the new **ES6** `class` form, this **class** can now be instantiated and used just as you'd expect:

```js
let f = new Hamed(15, 8);
console.log(f); // Hamed { x: 15, y: 8 }
console.log(f.x); // 15
console.log(f.y); // 8
console.log(f.fetchXY()); // 120
```

Caution! Though `class Hamed` seems much like `function Hamed()`, there are important differences:

- A `Hamed(..)` call of `class Hamed` must be made with `new`, as the pre-**ES6** option of `Hamed.call(obj)` will not work.
- While `function Hamed` is **hoisted**, `class Hamed` is not; the `extends ..` clause specifies an expression that cannot be **hoisted**. So, you must declare a `class` before you can instantiate it.
- `class Hamed` in the top global scope creates a lexical `Hamed` identifier in that scope, but unlike `function Hamed` does not create a global object property of that name.

The established `instanceof` operator still works with **ES6** classes, because `class` just creates a constructor function of the same name. However, **ES6** introduces a way to customize how `instanceof` works, using `Symbol.hasInstance`.

Another way of thinking about `class`, which we find more convenient, is as a macro that is used to automatically populate a `prototype` object. Optionally, it also wires up the `[[Prototype]]` relationship if using `extends`.

An **ES6** `class` isn't really an entity itself, but a meta concept that wraps around other concrete entities, such as functions and properties, and ties them together.

**Tip**: In addition to the declaration form, a `class` can also be an expression, as in: `let x = class Y { .. }` . This is primarily useful for passing a class definition (technically, the constructor itself) as a function argument or assigning it to an object property.

## `extends` and `super`

**ES6** classes also have syntactic sugar for establishing the `[[Prototype]]` delegation link between two function prototypes -- commonly mislabeled **inheritance** or confusingly labeled **prototype inheritance** -- using the class-oriented familiar terminology `extends`:

```js
class Hamid extends Hamed {
  constructor(a, b, c) {
    super(a, b);
    this.z = c;
  }

  fetchXY() {
    return super.fetchXY() * this.z;
  }
}

let b = new Hamid(5, 15, 25);

console.log(b.x); // 5
console.log(b.y); // 15
console.log(b.z); // 25
console.log(b.fetchXY()); // 1875
```

A significant new addition is `super`, which is actually something not directly possible pre-**ES6** (without some unfortunate hack trade-offs). In the constructor, `super` automatically refers to the **parent constructor**, which in the previous example is `Hamed(..)`. In a method, it refers to the **parent object**, such that you can then make a property/method access off it, such as `super.fetchXY()`.

`Hamid extends Hamed` of course means to link the `[[Prototype]]` of `Hamid.prototype` to `Hamed.prototype`. So, `super` in a method like `fetchXY` specifically means `Hamed.prototype`, whereas `super` means `Hamed` when used in the `Hamid` constructor.

**Note**: `super` is not limited to `class` declarations. It also works in **object literals**, in much the same way we're discussing here.

There may be cases where in the constructor you would want to reference the `Hamed.prototype`, such as to directly access one of its properties/methods. However, `super` in the constructor cannot be used in that way; `super.prototype` will not work. `super(..)` means roughly to call `new Hamed(..)`, but isn't actually a usable reference to `Hamed` itself.

Symmetrically, you may want to reference the `Hamed(..)` function from inside a non-constructor method. `super.constructor` will point at `Hamed(..)` the function, but beware that this function can only be invoked with `new`. `new super.constructor(..)` would be valid, but it wouldn't be terribly useful in most cases, because you can't make that call use or reference the current `this` object context, which is likely what you'd want.

Also, `super` looks like it might be driven by a function's context just like `this` -- that is, that they'd both be dynamically bound. However, `super` is not dynamic like `this` is. When a constructor or method makes a `super` reference inside it at declaration time (in the `class` body), that `super` is statically bound to that specific class hierarchy, and cannot be overridden (at least in **ES6**).

**Q**: What does that mean?

**Answer**: It means that if you're in the habit of taking a method from one **class** and **borrowing** it for another class by overriding its `this` , say with `call(..)` or `apply(..)`, that may very well create surprises if the method you're borrowing has a `super` in it. Consider this class hierarchy:

```js
class ParentA {
  constructor() { this.id = "a"; }
  xfunc() { console.log("ParentA:", this.id); }
}

class ParentB {
  constructor() { this.id = "b"; }
  xfunc() { console.log("ParentB:", this.id); }
}

class ChildA extends ParentA {
  xfunc() {
    super.xfunc();
    console.log("ChildA:", this.id);
  }
}

class ChildB extends ParentB {
  xfunc() {
    super.xfunc();
    console.log("ChildB:", this.id);
  }
}

let a = new ChildA();
a.xfunc(); // "ParentA: a" "ChildA: a"

let b = new ChildB();
b.xfunc(); // "ParentB: b" "ChildB: b"
```

borrow `b.func()` to use in `a` context:

```js
b.func.call(a); // "ParentB: a" "ChildB: a"
```

As you can see, the `this.id` reference was dynamically rebound so that `: a` is reported in both cases instead of `: b`. But `b.func()`'s `super.func()` reference wasn't dynamically rebound, so it still reported `ParentB` instead of the expected `ParentA`.

Because `b.func()` references `super`, it is statically bound to the `ChildB` / `ParentB` hierarchy and cannot be used against the `ChildA` / `ParentA` hierarchy. There is no **ES6** solution to this limitation.

The choice boils down to narrowing your object design to these static hierarchies -- `class`, `extends`, and `super` will be quite nice -- or dropping all attempts to **fake** classes and instead embrace dynamic and flexible, classless objects and `[[Prototype]]` delegation.

## Subclass Constructor

Constructors are not required for classes or subclasses; a default constructor is substituted in both cases if omitted. However, the default substituted constructor is different for a direct class versus an extended class.

Specifically, the default subclass constructor automatically calls the parent constructor, and passes along any arguments. In other words, you could think of the default subclass constructor sort of like this:

```js
constructor(...args) {
  super(...args);
}
```

This is an **important** detail to note. Not all class languages have the subclass constructor automatically call the parent constructor. C++ does, but Java does not. But more **importantly**, in pre-**ES6** classes, such automatic **parent constructor** calling does not happen. Be careful when converting to **ES6** `class` if you've been relying on such calls not happening.

Another perhaps surprising **deviation/limitation** of **ES6** subclass constructors: in a constructor of a subclass, you cannot access `this` until `super(..)` has been called. The reason is nuanced and complicated, but it boils down to the fact that the parent constructor is actually the one creating/initializing your instance's `this`. Pre-**ES6**, it works oppositely; the `this` object is created by the **subclass constructor**, and then you call a **parent constructor** with the context of the **subclass** `this`.

Let's illustrate. This works pre-**ES6**:

```js
function Hamed() {
  this.a = 1;
}

function Hamid() {
  this.b = 2;
  Hamed.call(this);
}

// `Hamid` "extends" `Hamed`
Hamid.prototype = Object.create(Hamed.prototype);
```

But this **ES6** equivalent is not allowed:

```js
class Hamed {
  constructor() { this.a = 1; }
}

class Hamid extends Hamed {
  constructor() {
    this.b = 2; // not allowed before `super()`
    super(); // to fix, swap these two statements
  }
}
```

In this case, the fix is simple. Just swap the two statements in the subclass `Hamid` constructor. However, if you've been relying pre-ES6 on being able to skip calling the **parent constructor**, beware because that won't be allowed anymore.

One of the most heralded benefits to the new `class` and `extend` design in the ability to subclass the built-in natives, like `Array`. Consider:

```js
class MyCoolArray extends Array {
  first() { return this[0]; }
  last() { return this[this.length - 1]; }
}

let a = new MyCoolArray(1, 2, 3, 4);
console.log(a.length); // 4
console.log(a); // "MyCoolArray(3)" [ 1, 2, 3, 4 ]
console.log(a.first()); // 1
console.log(a.last()); // 4
```

Other `Error` object example:

```js
class Oops extends Error {
  constructor(reason) {
    super(reason);
    this.oops = reason;
  }
}

// later:
let ouch = new Oops("I messed up!");
throw ouch; // Oops [Error]: "I messed up!"
```

## `new.target`

**ES6** introduces a new concept called a meta property, in the form of `new.target`.

If that looks strange, it is; pairing a keyword with a `.` and a property name is definitely an out-of-the-ordinary pattern for **JavaScript**.

`new.target` is a new **magical** value available in all functions, though in normal functions it will always be `undefined`. In any constructor, `new.target` always points at the constructor that `new` actually directly invoked, even if the constructor is in a parent class and was delegated to by a `super(..)` call from a child constructor. Consider:

```js
class Hamed {
  constructor() {
    console.log("Hamed: ", new.target.name);
  }
}

class Hamid extends Hamed {
  constructor() {
    super();
    console.log("Hamid: ", new.target.name);
  }
  ali() {
    console.log("ali: ", new.target);
  }
}

let a = new Hamed(); // "Hamed: " "Hamed"

let b = new Hamid();
// "Hamed: " "Hamid" < --respects the`new` call - site
// "Hamid: " "Hamid"

b.ali();
// "ali: " undefined
```

The `new.target` meta property doesn't have much purpose in class constructors, except accessing a static property/method.

If `new.target` is `undefined`, you know the function was not called with `new`. You can then force a `new` invocation if that's necessary.

When a subclass `Hamid` extends a parent class `Hamed`, we already observed that `Hamid.prototype` is `[[Prototype]]`-linked to `Hamed.prototype`. But additionally, `Hamid()` is `[[Prototype]]`-linked to `Hamed()`. That part may not have such an obvious reasoning.

## `Symbol.species` Constructor Getter

Many methods on `Array` create and return a new `Array` instance. If you define a derived class from `Array`, but you want those methods to continue to vend actual `Array` instances instead of from your derived class, this works:

```js
class MyCoolArray extends Array {
  // force `species` to be parent constructor
  static get [Symbol.species]() { return Array; }
}

var a = new MyCoolArray(1, 2, 3),
  b = a.map(function (v) { return v * 2; });

console.log(b instanceof MyCoolArray); // false
console.log(b instanceof Array); // true
```

To illustrate how a parent class method can use a child's species declaration somewhat like `Array#map(..)` is doing, consider:

```js
class Hamed {
  // defer `species` to derived constructor
  static get [Symbol.species]() { return this; }
  spawn() {
    return new this.constructor[Symbol.species]();
  }
}

class Hamid extends Hamed {
  // force `species` to be parent constructor
  static get [Symbol.species]() { return Hamed; }
}

var a = new Hamed();
var b = a.spawn();
console.log(b instanceof Hamed); // true

var x = new Hamid();
var y = x.spawn();
console.log(y instanceof Hamid); // false
console.log(y instanceof Hamed); // true
```

The parent class `Symbol.species` does `return this` to defer to any derived class, as you'd normally expect. `Hamid` then overrides to manually declare `Hamed` to be used for such instance creation. Of course, a derived class can still vend instances of itself using `new this.constructor(..)`.

What did we learn from `iterator` to `class`:

**ES6** introduces several new features that aid in code organization:

- Iterators provide sequential access to data or operations. They can be consumed by new language features like `for..of` and `...` .
- Generators are locally pause/resume capable functions controlled by an iterator. They can be used to programmatically (and interactively, through `yield` / `next(..)` message passing) generate values to be consumed via iteration.
- Modules allow private encapsulation of implementation details with a publicly exported API. Module definitions are file-based, singleton instances, and statically resolved at compile time.
- Classes provide cleaner syntax around prototype-based coding. The addition of `super` also solves tricky issues with relative references in the `[[Prototype]]` chain.

These new tools should be your first stop when trying to improve the architecture of your **JavaScript** projects by embracing **ES6**.

**ES6** adds a new feature that helps address significant shortcomings in the callbacks-only approach to async: **Promises**. In addition, we can revisit generators (from the previous chapter) and see a pattern for combining the two that's a major step forward in async flow control programming in **JavaScript**.

---
<!-- Async Flow Control -->
## Promises

Promises are not about replacing callbacks. Promises provide a trustable intermediary -- that is, between your calling code and the async code that will perform the task -- to manage callbacks.

Another way of thinking about a Promise is as an event listener, on which you can register to listen for an event that lets you know when a task has completed. It's an event that will only ever fire once, but it can be thought of as an event nonetheless.

Promises can be chained together, which can sequence a series of asychronously completing steps. Together with higher-level abstractions like the `all(..)` method (in classic terms, a **gate**) and the `race(..)` method (in classic terms, a **latch**), promise chains provide a mechanism for **async flow control**.

Yet another way of conceptualizing a Promise is that it's a future value, a time-independent container wrapped around a value. This container can be reasoned about identically whether the underlying value is final or not. Observing the resolution of a Promise extracts this value once available. In other words, a Promise is said to be the async version of a sync function's return value.

A Promise can only have one of two possible resolution outcomes: **fulfilled** or **rejected**, with an optional single value. If a Promise is fulfilled, the final value is called a fulfillment. If it's rejected, the final value is called a reason (as in, a **reason for rejection**). Promises can only be resolved (**fulfillment** or **rejection**) once. Any further attempts to fulfill or reject are simply ignored. Thus, once a Promise is resolved, it's an immutable value that cannot be changed.

## Making and Using Promises

To construct a promise instance, use the `Promise(..)` constructor:

```js
let pm = new Promise(function pr(resolve, reject) {
  // do something
});
```

The `Promise(..)` constructor takes a single function (`pr(..)`), which is called immediately and receives two control functions as arguments, usually named `resolve(..)` and `reject()`. They are used as:

- if you call `reject(..)`, the promise is rejected, and if any value is passed to `reject(..)`, it is set as the reason for rejection.
- If you call `resolve(..)` with no value, or any non-promise value, the promise is fulfilled.
- If you call `resolve(..)` and pass another promise, this promise simply adopts the state -- whether immediate or eventual -- of the passed promise (either fulfillment or rejection).

Here's how you'd typically use a promise to refactor a callback-reliant function call. If you start out with an `ajax(..)` utility that expects to be able to call an error-first style callback:

```js
function ajax(url, callback) {
  // make request, eventually call `callback(..)`
}

// ...

ajax("http://some.url.1", function handler(err, contents) {
  if (err) {
    // handle ajax error
  }
  else {
    // handle `contents` success
  }
});
```

You can convert it to:

```js
function ajax(url) {
  return new Promise(function pr(resolve, reject) {
    /* make request, eventually call
     either `resolve(..)` or `reject(..)` */
  });
}

// ...

ajax("http://some.url.1")
  .then(
    function fulfilled(contents) {
      // handle `contents` success
    },
    function rejected(reason) {
      // handle ajax error reason
    }
  );
```

Promises have a `then(..)` method that accepts one or two callback functions. The first function (if present) is treated as the handler to call if the promise is fulfilled successfully. The second function (if present) is treated as the handler to call if the promise is rejected explicitly, or if any error/exception is caught during resolution.

If one of the arguments is omitted or otherwise not a valid function -- typically you'll use `null` instead -- a default placeholder equivalent is used. The default success callback passes its fulfillment value along and the default error callback propagates its rejection reason along.

The shorthand for calling `then(null,handleRejection)` is `catch(handleRejection)`.

Both `then(..)` and `catch(..)` automatically construct and return another promise instance, which is wired to receive the resolution from whatever the return value is from the original promise's fulfillment or rejection handler (whichever is actually called). Consider:

```js
ajax("http://some.url.1")
  .then(
    function fulfilled(contents) {
      return contents.toUpperCase();
    },
    function rejected(reason) {
      return "DEFAULT VALUE";
    }
  )
  .then(function fulfilled(data) {
    // handle data from original promise's
    // handlers
  });
```

In this snippet, we're returning an immediate value from either `fulfilled(..)` or `rejected(..)`, which then is received on the next event turn in the second `then(..)`'s `fulfilled(..)`. If we instead return a new promise, that new promise is subsumed and adopted as the resolution:

```js
ajax("http://some.url.1")
  .then(
    function fulfilled(contents) {
      return ajax(
        "http://some.url.2?v=" + contents
      );
    },
    function rejected(reason) {
      return ajax(
        "http://backup.url.3?err=" + reason
      );
    }
  )
  .then(function fulfilled(contents) {
    // `contents` comes from the subsequent
    // `ajax(..)` call, whichever it was
  });
```

It's important to note that an exception (or rejected promise) in the first `fulfilled(..)` will not result in the first `rejected(..)` being called, as that handler only responds to the resolution of the first original promise. Instead, the second promise, which the second `then(..)` is called against, receives that rejection.

In this previous snippet, we are not listening for that rejection, which means it will be silently held onto for future observation. If you never observe it by calling a `then(..)` and `catch(..)`, then it will go unhandled. Some browser developer consoles may detect these unhandled rejections and report them, but this is not reliably guaranteed; you should always observe promise rejections.

**Note**: This was just a brief overview of Promise theory and behavior. For a much more in-depth exploration, see async.md file (Asynchrony - before callback).

## Thenables

Promises are genuine instances of the `Promise(..)` constructor. However, there are promise-like objects called thenables that generally can interoperate with the Promise mechanisms.

Any object (or function) with a `then(..)` function on it is assumed to be a thenable. Any place where the Promise mechanisms can accept and adopt the state of a genuine promise, they can also handle a thenable.

Thenables are basically a general label for any promise-like value that may have been created by some other system than the actual `Promise(..)` constructor. In that perspective, a thenable is generally less trustable than a genuine Promise. Consider this misbehaving thenable, for example:

```js
let th = {
  then: function thener(fulfilled) {
    // call `fulfilled(..)` once every 100ms forever
    setInterval(fulfilled, 100);
  }
};
```

If you received that thenable and chained it with `th.then(..)`, you'd likely be surprised that your fulfillment handler is called repeatedly, when normal Promises are supposed to only ever be resolved once.

The onus (obligation) will be on you to guard against directly using values with the Promise mechanism that would be incorrectly assumed to be a thenable.

## `Promise` API

The `Promise` API also provides some static methods for working with Promises.

`Promise.resolve(..)` creates a promise resolved to the value passed in. Let's compare how it works to the more manual approach:

```js
let pm1 = Promise.resolve(23);
let pm2 = new Promise(function pr(resolve) {
  resolve(23);
});
```

`pm1` and `pm2`  will have essentially identical behavior. The same goes for resolving with a promise:

```js
let theP = ajax();
let pm1 = Promise.resolve(23);
let pm2 = new Promise(function pr(resolve) {
    resolve(23);
});
```

`Promise.reject(..)` creates an immediately rejected promise, the same as its `Promise` constructor counterpart:

```js
let pm1 = Promise.reject("Oh No!");
let pm2 = new Promise(function pr(resolve, reject) {
  reject("Oh No!");
});
```

While `resolve(..)` and `Promise.resolve(..)` can accept a promise and adopt its state/resolution, `reject(..)` and `Promise.reject(..)` do not differentiate what value they receive. So, if you reject with a promise or thenable, the promise/thenable itself will be set as the rejection reason, not its underlying value.

`Promise.all([ .. ])` accepts an array of one or more values (e.g., immediate values, promises, thenables). It returns a promise back that will be fulfilled if all the values fulfill, or reject immediately once the first of any of them rejects.

Starting with these values/promises:

```js
let pm1 = Promise.resolve(23);
let pm2 = new Promise(function pr(resolve) {
  setTimeout(function () {
    resolve(24);
  }, 100);
});
let value3 = 25;
let pm4 = new Promise(function pr(resolve, reject) {
  setTimeout(function () {
    reject("Oops");
  }, 10);
});
```

Let's consider how `Promise.all([ .. ])` works with combinations of those values:

```js
Promise.all([pm1, pm2, value3])
  .then(function fulfilled(vals) {
    console.log(vals); // [23,24,25]
  });

Promise.all([pm1, pm2, value3, pm4])
  .then(
    function fulfilled(vals) {
      // never gets here
    },
    function rejected(reason) {
      console.log(reason);
      // "Oh No!"
    }
  );
```

While `Promise.all([ .. ])` waits for all fulfillments (or the first rejection), `Promise.race([ .. ])` waits only for either the first fulfillment or rejection. Consider:

```js
// NOTE: re-setup all test values to
// avoid timing issues misleading you!
Promise.race([pm2, pm1, value3])
  .then(function fulfilled(val) {
    console.log(val); // 23
  });

Promise.race([pm2, pm4])
  .then(
    function fulfilled(val) {
      // never gets here
    },
    function rejected(reason) {
      console.log(reason);
      // "Oh No!"
    }
  );
```

**Warning**: While `Promise.all([])` will fulfill right away (with no values), `Promise.race([])` will hang forever. This is a strange inconsistency, and speaks to the suggestion that you should never use these methods with empty arrays.

## Generators + Promises (text mode)

A generator can yield a promise, and that promise can then be wired to resume the generator with its fulfillment value.

Why are we using Promises with the generator? It's certainly possible to do async generator coding without Promises.

Promises are a trustable system that uninverts the inversion of control of normal callbacks or thunks.

So, combining the trustability of Promises and the synchronicity of code in generators effectively addresses all the major deficiencies of callbacks.

Also, utilities like `Promise.all([ .. ])` are a nice, clean way to express concurrency at a generator's single `yield` step.

**Note**: For a more prolifically commented version of this utility, see the async.md (and performance.md) file.

Essentially, anywhere that you have more than two asynchronous steps of flow control logic in your program, you can and should use a promise-yielding generator driven by a run utility to express the flow control in a synchronous fashion. This will make for much easier to understand and maintain code.

---
<!-- Collections -->
## TypedArrays

As we cover in the `types.md` and `grammer.md`, **JavaScript** does have a set of built-in types, like `number` and `string`. It'd be tempting to look at a feature named **typed array** and assume it means an array of a specific type of values, like an array of only strings.

How do you construct such a bit-bucket? It's called a **buffer**, and you construct it most directly with the `ArrayBuffer(..)` constructor:

```js
let buf = new ArrayBuffer(32);
console.log(buf.byteLength); // 32
```

`buf` is now a binary buffer that is 32-bytes long (256-bits), that's pre-initialized to all `0`s. A buffer by itself doesn't really allow you any interaction exception for checking its `byteLength` property.

But on top of this array buffer, you can then layer a **view**, which comes in the form of a typed array. Consider:

```js
let buf = new ArrayBuffer(32);
console.log(buf.byteLength); // 32

let array = new Uint16Array(buf);
console.log(array.length); // 16
```

`array` is a typed array of 16-bit unsigned integers mapped over the 256-bit `buf` buffer, meaning you get 16 elements.

Let's imagine the base-10 number `3085`, which takes 16-bits to represent. If you have just one 16-bit number container, it'd be represented in binary as `0000110000001101` (hexadecimal `0c0d`) regardless of endianness.

But if `3085` was represented with two 8-bit numbers, the endianness would significantly affect its storage in memory:

- `0000110000001101` / `0c0d` (big endian)
- `0000110100001100` / `0d0c` (little endian)

If you received the bits of `3085` as `0000110100001100` from a little-endian system, but you layered a view on top of it in a big-endian system, you'd instead see value `3340` (base-10) and `0d0c` (base-16).

## Multiple Views

A single buffer can have multiple views attached to it, such as:

```js
let buf = new ArrayBuffer(2);

let view8 = new Uint8Array(buf);
let view16 = new Uint16Array(buf);

view16[0] = 3085;
console.log(view8[0]); // 13
console.log(view8[1]); // 12

console.log(view8[0].toString(16)); // "d"
console.log(view8[1].toString(16)); // "c"

// swap (as if endian!)
let tmp = view8[0];
view8[0] = view8[1];
view8[1] = tmp;

console.log(view16[0]); // 3340
```

The typed array constructors have multiple signature variations. We've shown so far only passing them an existing buffer. However, that form also takes two extra parameters: `byteOffset` and `length`. In other words, you can start the typed array view at a location other than `0` and you can make it span less than the full length of the buffer.

If the buffer of binary data includes data in non-uniform size/location, this technique can be quite useful.

For example, consider a binary buffer that has a 2-byte number (aka **word**) at the beginning, followed by two 1-byte numbers, followed by a 32-bit floating point number. Here's how you can access that data with multiple views on the same buffer, offsets, and lengths:

```js
let first = new Uint16Array(buf, 0, 2)[0],
  second = new Uint8Array(buf, 2, 1)[0],
  third = new Uint8Array(buf, 3, 1)[0],
  fourth = new Float32Array(buf, 4, 4)[0];
```

One interesting behavior to consider is that TypedArrays have a `sort(..)` method much like regular arrays, but this one defaults to numeric sort comparisons instead of coercing values to strings for lexicographic comparison. For example:

```js
let a = [10, 1, 2];
console.log(a.sort()); // [ 1, 10, 2 ]

let b = new Uint8Array([10, 1, 2]);
console.log(b.sort()); // "Uint8Array(3)" [ 1, 2, 10 ]
```

## Maps

If you have a lot of **JavaScript**` experience, you know that objects are the primary mechanism for creating unordered key/value-pair data structures, otherwise known as **maps**. However, the major drawback with objects-as-maps is the inability to use a non-string value as the key. For example, consider:

```js
let map = {};

let x = { id: 1 };
let y = { id: 2 };

map[x] = "hamed";
map[y] = "hamid";
console.log(map[x]); // "hamid"
console.log(map[y]); // "hamid"
```

What's going on here? The two objects `x` and `y` both stringify to `"[object Object]"`, so only that **one key** is being set in `map`.

Some have implemented fake maps by maintaining a parallel array of non-string keys alongside an array of the values, such as:

```js
let keys = [], vals = [];

let x = { id: 1 },
  y = { id: 2 };

keys.push(x);
vals.push("hamed");

keys.push(y);
vals.push("hamid");

console.log(keys[0] === x); // true
console.log(vals[0]); // "hamed"

console.log(keys[1] === y); // true
console.log(vals[1]); // "hamid"
```

Of course, you wouldn't want to manage those parallel arrays yourself, so you could define a data structure with methods that automatically do the management under the covers. Besides having to do that work yourself, the main drawback is that access is no longer O(1) time-complexity, but instead is O(n).

But as of **ES6**, there's no longer any need to do this! Just use `Map(..)`:

```js
let map = new Map();

let x = { id: 1 };
let y = { id: 2 };

map.set(x, "hamed");
map.set(y, "hamid");

console.log(map.get(x)); // "hamed"
console.log(map.get(y)); // "hamid"
```

The only drawback is that you can't use the `[]` bracket access syntax for setting and retrieving values. But `get(..)` and `set(..)` work perfectly suitably instead.

To delete an element from a map, don't use the `delete` operator, but instead use the `delete(..)` method:

```js
let map = new Map();

let x = { id: 1 };
let y = { id: 2 };

map.set(x, "hamed");
map.set(y, "hamid");

console.log(map.get(x)); // "hamed"
console.log(map.get(y)); // "hamid"

map.delete(y);
console.log(map.get(y)); // undefined
```

You can clear the entire map's contents with `clear()`. To get the length of a map (i.e., the number of keys), use the `size` property (not `length`):

```js
let map = new Map();

let x = { id: 1 };
let y = { id: 2 };

map.set(x, "hamed");
map.set(y, "hamid");

console.log(map.size); // 2
map.clear();
console.log(map.size); // 0
```

The `Map(..)` constructor can also receive an iterable, which must produce a list of arrays, where the first item in each array is the key and the second item is the value. This format for iteration is identical to that produced by the `entries()` method. That makes it easy to make a copy of a map:

```js
let map2 = new Map(map.entries());

// same as:
let map2 = new Map(map);
```

Because a map instance is an iterable, and its default iterator is the same as `entries()`, the second shorter form is more preferable.

Of course, you can just manually specify an entries list (array of key/value arrays) in the `Map(..)` constructor form:

```js
let x = { id: 1 },
  y = { id: 2 };

let map = new Map([
  [x, "hamed"],
  [y, "hamid"]
]);

console.log(map.get(x)); // "hamed"
console.log(map.get(y)); // "hamid"
```

## Map Values

To get the list of values from a map, use `values(..)`, which returns an iterator.

```js
let map = new Map();

let x = { id: 1 },
  y = { id: 2 };

map.set(x, "hamed");
map.set(y, "hamid");

let val = [...map.values()];

console.log(val); // [ 'hamed', 'hamid' ]
console.log(Array.from(map.values())); // [ 'hamed', 'hamid' ]
```

As discussed in the previous section, you can iterate over a map's entries using `entries()` (or the default map iterator). Consider:

```js
let map = new Map();

let x = { id: 1 },
  y = { id: 2 };

map.set(x, "hamed");
map.set(y, "hamid");

let vals = [...map.entries()];

console.log(vals[0][0] === x); // true
console.log(vals[0][1]); // "hamed"

console.log(vals[1][0] === y); // true
console.log(vals[1][1]); // "hamid"
```

## Map Keys

To get the list of keys, use `keys()`, which returns an iterator over the keys in the map:

```js
let map = new Map();

let x = { id: 1 },
  y = { id: 2 };

map.set(x, "hamed");
map.set(y, "hamid");

let keys = [...map.keys()];

console.log(keys[0] === x); // true
console.log(keys[1] === y); // true
```

To determine if a map has a given key, use `has(..)`:

```js
let map = new Map();

let x = { id: 1 },
  y = { id: 2 };

map.set(x, "hamed");
map.set(y, "hamid");

console.log(map.has(x)); // true
console.log(map.has(y)); // true
```

Maps essentially let you associate some extra piece of information (the value) with an object (the key) without actually putting that information on the object itself.

While you can use any kind of value as a key for a map, you typically will use objects, as strings and other primitives are already eligible as keys of normal objects. In other words, you'll probably want to continue to use normal objects for maps unless some or all of the keys need to be objects, in which case map is more appropriate.

Warning: If you use an object as a map key and that object is later discarded (all references unset) in attempt to have garbage collection (GC) reclaim its memory, the map itself will still retain its entry. You will need to remove the entry from the map for it to be GC-eligible. In the next section, we'll see WeakMaps as a better option for object keys and GC.

## WeakMaps

WeakMaps are a variation on maps, which has most of the same external behavior but differs underneath in how the memory allocation (specifically its GC) works.

WeakMaps take (**only**) objects as keys. Those objects are held weakly, which means if the object itself is GC'd, the entry in the **WeakMap** is also removed.

The API for WeakMap is similar, though more limited:

```js
let map = new WeakMap();

let x = { id: 1 },
  y = { id: 2 };

map.set(x, "hamed");
map.set(y, "hamid");

console.log(map.has(x)); // true
console.log(map.has(y)); // true
```

It's important to note that a WeakMap only holds its keys weakly, not its values. Consider:

```js
let map = new WeakMap();

let x = { id: 1 },
  y = { id: 2 },
  z = { id: 3 },
  w = { id: 4 };

map.set(x, y);

x = null;
y = null;
// { id: 1 } is GC-eligible
// { id: 2 } is GC-eligible
// only because { id: 1 } is

map.set(z, w);

w = null;
// { id: 4 } is not GC-eligible
```

## Sets

A set is a collection of unique values (duplicates are ignored).

The API for a set is similar to map. The `add(..)` method takes the place of the `set(..)` method (somewhat ironically), and there is no `get(..)` method. Consider:

```js
let set = new Set();

let x = { id: 1 },
  y = { id: 2 };

set.add(x);
set.add(y);
set.add(x);

console.log(set.size); // 2

set.delete(y);
console.log(set.size); // 1

set.clear();
console.log(set.size); // 0
```

The `Set(..)` constructor form is similar to `Map(..)`, in that it can receive an iterable, like another set or simply an array of values. However, unlike how `Map(..)` expects entries list (array of key/value arrays), `Set(..)` expects a values list (array of values):

```js
let x = { id: 1 },
  y = { id: 2 };

let set = new Set([x, y]);
```

A Set doesn't need a `get(..)` because you don't retrieve a value from a set, but rather test if it is present or not, using `has(..)`:

```js
let set = new Set();

let x = { id: 1 },
  y = { id: 2 };

set.add(x);

console.log(set.has(x)); // true
console.log(set.has(y)); // false
```

**Note**: The comparison algorithm in `has(..)` is almost identical to `Object.is(..)`, except that `-0` and `0` are treated as the same rather than distinct.

## Set Iterators

Sets have the same iterator methods as maps. Their behavior is different for sets, but symmetric with the behavior of map iterators. Consider:

```js
var set = new Set();

var x = { id: 1 },
  y = { id: 2 };

set.add(x).add(y);

var keys = [...set.keys()],
  vals = [...set.values()],
  entries = [...set.entries()];

console.log(keys[0] === x); // true
console.log(keys[1] === y);  // true

console.log(vals[0] === x);  // true
console.log(vals[1] === y);  // true
console.log(entries[0][0] === x);  // true
console.log(entries[0][1] === x);  // true
console.log(entries[1][0] === y);  // true
console.log(entries[1][1] === y);  // true
```

The `keys()` and `values()` iterators both yield a list of the unique values in the set. The `entries()` iterator yields a list of entry arrays, where both items of the array are the unique set value. The default iterator for a set is its `values()` iterator.

The inherent uniqueness of a set is its most useful trait. For example:

```js
let set = new Set([1, 2, 3, 4, "1", 2, 4, "5"]),
  uniques = [...set];

console.log(uniques); // [ 1, 2, 3, 4, '1', '5' ]
```

Set uniqueness does not allow coercion, so `1` and `"1"` are considered distinct values.

## WeakSets

Whereas a WeakMap holds its keys weakly (but its values strongly), a WeakSet holds its values weakly (there aren't really keys).

```js
let set = new WeakSet();

let x = { id: 1 },
  y = { id: 2 };

set.add(x);
set.add(y);

x = null; // `x` is GC-eligible
y = null; // `y` is GC-eligible
```

**Warning**: WeakSet values must be objects, not primitive values as is allowed with sets.

---
<!-- API Additions -->
## `Array`

One of the most commonly extended features in **JavaScript** by various user libraries is the Array type. It should be no surprise that **ES6** adds a number of helpers to Array, both static and prototype (instance).

## `Array.of(..)` Static Function

`Array.of(..)` replaces `Array(..)` as the preferred function-form constructor for arrays, because `Array.of(..)` does not have that special single-number-argument case. Consider:

```js

```
